{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "from collections import Counter\n",
    "import csv\n",
    "import config\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "import subprocess\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from collections import OrderedDict, defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import fnmatch\n",
    "#from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from src.CustomTokenizer import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from data_processing.preprocessing import get_dataset_text, get_word_index_list, write_index_to_file, read_index_as_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training file from path:  /home/sukanya/PhD/Datasets/PAN SCD/pan19-style-change-detection/processed/train.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18961, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading training file from path: \", config.config_io.get('pan_19_processed_train'))\n",
    "training_data = pd.read_csv(config.config_io.get('pan_19_processed_train'))\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>author_1</th>\n",
       "      <th>author_2</th>\n",
       "      <th>para1_text</th>\n",
       "      <th>para2_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem-1543.txt</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>Given an alphabet $\\Sigma$ of size $k$ and two...</td>\n",
       "      <td>\\nThe paper \"Algorithmic Meta Theorems for Cir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem-631.txt</td>\n",
       "      <td>A1</td>\n",
       "      <td>A3</td>\n",
       "      <td>\\nInstead of an actual GPS device, I would rec...</td>\n",
       "      <td>In the end, a seat post pump probably has the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>problem-631.txt</td>\n",
       "      <td>A3</td>\n",
       "      <td>A2</td>\n",
       "      <td>In the end, a seat post pump probably has the ...</td>\n",
       "      <td>\\nThanks for the help. Finally what I needed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem-631.txt</td>\n",
       "      <td>A2</td>\n",
       "      <td>A1</td>\n",
       "      <td>\\nThanks for the help. Finally what I needed t...</td>\n",
       "      <td>\\nIt might sound weird, but if you're finding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem-631.txt</td>\n",
       "      <td>A1</td>\n",
       "      <td>A2</td>\n",
       "      <td>\\nIt might sound weird, but if you're finding ...</td>\n",
       "      <td>This is a bit weird question. I bought a Speci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            problem author_1 author_2  \\\n",
       "0  problem-1543.txt       A1       A1   \n",
       "1   problem-631.txt       A1       A3   \n",
       "2   problem-631.txt       A3       A2   \n",
       "3   problem-631.txt       A2       A1   \n",
       "4   problem-631.txt       A1       A2   \n",
       "\n",
       "                                          para1_text  \\\n",
       "0  Given an alphabet $\\Sigma$ of size $k$ and two...   \n",
       "1  \\nInstead of an actual GPS device, I would rec...   \n",
       "2  In the end, a seat post pump probably has the ...   \n",
       "3  \\nThanks for the help. Finally what I needed t...   \n",
       "4  \\nIt might sound weird, but if you're finding ...   \n",
       "\n",
       "                                          para2_text  \n",
       "0  \\nThe paper \"Algorithmic Meta Theorems for Cir...  \n",
       "1  In the end, a seat post pump probably has the ...  \n",
       "2  \\nThanks for the help. Finally what I needed t...  \n",
       "3  \\nIt might sound weird, but if you're finding ...  \n",
       "4  This is a bit weird question. I bought a Speci...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['problem', 'author_1', 'author_2', 'para1_text', 'para2_text'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing file from path:  /home/sukanya/PhD/Datasets/PAN SCD/pan19-style-change-detection/processed/test.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9538, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading testing file from path: \", config.config_io.get('pan_19_processed_test'))\n",
    "testing_data = pd.read_csv(config.config_io.get('pan_19_processed_test'))\n",
    "testing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>author_1</th>\n",
       "      <th>author_2</th>\n",
       "      <th>para1_text</th>\n",
       "      <th>para2_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem-631.txt</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>Update\\nTurns out the fuel pump, filter and re...</td>\n",
       "      <td>The door lock/unlock relays are built into the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem-631.txt</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>The door lock/unlock relays are built into the...</td>\n",
       "      <td>\\nThe knuckle is the part the spindle attaches...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>problem-631.txt</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>\\nThe knuckle is the part the spindle attaches...</td>\n",
       "      <td>You would have to set the scope to the scale o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem-631.txt</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>You would have to set the scope to the scale o...</td>\n",
       "      <td>\\nCheck for an exhaust leak before or right af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem-631.txt</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>\\nCheck for an exhaust leak before or right af...</td>\n",
       "      <td>Yes, a p0340 code can cause a no start as the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           problem author_1 author_2  \\\n",
       "0  problem-631.txt       A1       A1   \n",
       "1  problem-631.txt       A1       A1   \n",
       "2  problem-631.txt       A1       A1   \n",
       "3  problem-631.txt       A1       A1   \n",
       "4  problem-631.txt       A1       A1   \n",
       "\n",
       "                                          para1_text  \\\n",
       "0  Update\\nTurns out the fuel pump, filter and re...   \n",
       "1  The door lock/unlock relays are built into the...   \n",
       "2  \\nThe knuckle is the part the spindle attaches...   \n",
       "3  You would have to set the scope to the scale o...   \n",
       "4  \\nCheck for an exhaust leak before or right af...   \n",
       "\n",
       "                                          para2_text  \n",
       "0  The door lock/unlock relays are built into the...  \n",
       "1  \\nThe knuckle is the part the spindle attaches...  \n",
       "2  You would have to set the scope to the scale o...  \n",
       "3  \\nCheck for an exhaust leak before or right af...  \n",
       "4  Yes, a p0340 code can cause a no start as the ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the feature set files\n",
    "We are doing it manually now for greater control. In the future, we must automate to read the files directly form the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index files\n",
    "\n",
    "feature_set_files = { 'opt1':\n",
    "['/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/50word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/100word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/150word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/200word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/250word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/300word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/350word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/400word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/450word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/500word_list.txt'],\n",
    "                    'opt2':\n",
    "['/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/50word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/100word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/150word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/200word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/250word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/300word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/350word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/400word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/450word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/500word_list.txt'],\n",
    "                    'opt3':\n",
    "['/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/50word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/100word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/150word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/200word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/250word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/300word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/350word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/400word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/450word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/500word_list.txt'],\n",
    "                    'opt4':\n",
    "['/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/50word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/100word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/150word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/200word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/250word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/300word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/350word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/400word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/450word_list.txt',\n",
    "'/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/500word_list.txt']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = English()\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7fc9917a1130>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7fca60666100>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7fc9919c1fa0>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'very', 'large', 'line', 'this', 'is', 'i', 'do', \"n't\", 'know', 'how', 'this', 'works', 'yet', '!', 'god', 'save', 'me', '!', '!']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'very', 'large', 'line', 'this', 'is', 'i', 'do', \"n't\", 'know', 'how', 'this', 'works', 'yet', '!', 'god', 'save', 'me', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "# takes micro seconds 90.7 µs ± 962 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each), 100 times faster than below loop\n",
    "def custom_analyzer(text):\n",
    "    #doc = nlp(text.lower())\n",
    "    doc = list(nlp.pipe([text.lower()], disable=[\"tagger\", \"parser\",\"ner\"]))[0]\n",
    "    return [t.text for t in doc]\n",
    "\n",
    "print(custom_analyzer(\"A very large line this is I don't know how this works yet! God Save me!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt1/50word_list.txt\n",
      ". ,   's n't    like one 'm get time urllink know really go well would     got think people good day back going see much love went today could want nt even life 've way 'll still say last things work make first new something right us ca\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'opt1': ['/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt1/50word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt1/100word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt1/150word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt1/200word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt1/250word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt1/300word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt1/350word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt1/400word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt1/450word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt1/500word_list.txt'],\n",
       " 'opt2': ['/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt2/50word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt2/100word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt2/150word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt2/200word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt2/250word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt2/300word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt2/350word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt2/400word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt2/450word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt2/500word_list.txt'],\n",
       " 'opt3': ['/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt3/50word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt3/100word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt3/150word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt3/200word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt3/250word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt3/300word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt3/350word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt3/400word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt3/450word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt3/500word_list.txt'],\n",
       " 'opt4': ['/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt4/50word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt4/100word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt4/150word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt4/200word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt4/250word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt4/300word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt4/350word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt4/400word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt4/450word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNetworkTensorflow/src/baseline_with_Spacy/word_index/opt4/500word_list.txt']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes mili seconds 4.23 ms ± 124 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "'''def custom_analyzer(text):\n",
    "    doc = nlp(text.lower())\n",
    "    #doc = list(nlp.pipe([text.lower()], disable=[\"tagger\", \"parser\",\"ner\"]))[0]\n",
    "    return [t.text for t in doc]\n",
    "\n",
    "print(custom_analyzer(\"A very large line this is I don't know how this works yet! God Save me!!\"))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'opt1': ['/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/50word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/100word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/150word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/200word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/250word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/300word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/350word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/400word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/450word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/500word_list.txt'],\n",
       " 'opt2': ['/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/50word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/100word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/150word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/200word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/250word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/300word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/350word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/400word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/450word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/500word_list.txt'],\n",
       " 'opt3': ['/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/50word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/100word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/150word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/200word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/250word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/300word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/350word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/400word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/450word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/500word_list.txt'],\n",
       " 'opt4': ['/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/50word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/100word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/150word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/200word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/250word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/300word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/350word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/400word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/450word_list.txt',\n",
       "  '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/500word_list.txt']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt1\n",
      "opt1 ['/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/50word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/100word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/150word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/200word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/250word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/300word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/350word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/400word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/450word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt1/500word_list.txt']\n",
      "the to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when\n",
      "Epoch 1/30\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.6955 - accuracy: 0.5083WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0078s vs `on_test_batch_end` time: 0.0134s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6927 - accuracy: 0.5175 - val_loss: 0.6879 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6957 - accuracy: 0.5587 - val_loss: 0.6852 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6888 - accuracy: 0.5669 - val_loss: 0.6840 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6840 - accuracy: 0.5844 - val_loss: 0.6822 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6725 - accuracy: 0.6144 - val_loss: 0.6837 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6883 - accuracy: 0.5575 - val_loss: 0.6788 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6771 - accuracy: 0.5944 - val_loss: 0.6800 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6694 - accuracy: 0.6169 - val_loss: 0.6796 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6846 - accuracy: 0.5619 - val_loss: 0.6755 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6831 - accuracy: 0.5506 - val_loss: 0.6766 - val_accuracy: 0.5804\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6831 - accuracy: 0.5587 - val_loss: 0.6743 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6722 - accuracy: 0.6019 - val_loss: 0.6734 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6741 - accuracy: 0.5656 - val_loss: 0.6785 - val_accuracy: 0.5778\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6874 - accuracy: 0.5156 - val_loss: 0.6725 - val_accuracy: 0.5717\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.6727 - accuracy: 0.5763 - val_loss: 0.6727 - val_accuracy: 0.5794\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6612 - accuracy: 0.6263 - val_loss: 0.6826 - val_accuracy: 0.5794\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6621 - accuracy: 0.6187 - val_loss: 0.6766 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 4s - loss: 0.6155 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_test_batch_end` time: 0.0182s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6722 - accuracy: 0.5877\n",
      "training acc:  0.6187499761581421 , training loss:  0.6621383428573608 , val acc:  0.5793776512145996 , val loss:  0.6766393184661865 , test acc:  0.5876677632331848 , test loss:  0.6721581816673279\n",
      "\n",
      "the to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6906 - accuracy: 0.5625 - val_loss: 0.6831 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6881 - accuracy: 0.5475 - val_loss: 0.6784 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6761 - accuracy: 0.5875 - val_loss: 0.6762 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6828 - accuracy: 0.5600 - val_loss: 0.6754 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6757 - accuracy: 0.5731 - val_loss: 0.6733 - val_accuracy: 0.5630\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6827 - accuracy: 0.5650 - val_loss: 0.6814 - val_accuracy: 0.5707\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6786 - accuracy: 0.5719 - val_loss: 0.6717 - val_accuracy: 0.5783\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6800 - accuracy: 0.5500 - val_loss: 0.6722 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6726 - accuracy: 0.5519 - val_loss: 0.6703 - val_accuracy: 0.5694\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6767 - accuracy: 0.5512 - val_loss: 0.6698 - val_accuracy: 0.5725\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6862 - accuracy: 0.5487 - val_loss: 0.6694 - val_accuracy: 0.5638\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6621 - accuracy: 0.5956 - val_loss: 0.6685 - val_accuracy: 0.5715\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6647 - accuracy: 0.5913 - val_loss: 0.6735 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6674 - accuracy: 0.5938 - val_loss: 0.6738 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6622 - accuracy: 0.6162 - val_loss: 0.6693 - val_accuracy: 0.5723\n",
      "  1/596 [..............................] - ETA: 5s - loss: 0.6494 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0064s vs `on_test_batch_end` time: 0.0146s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6656 - accuracy: 0.5796\n",
      "training acc:  0.6162499785423279 , training loss:  0.6622275710105896 , val acc:  0.572257399559021 , val loss:  0.6693333387374878 , test acc:  0.5795931220054626 , test loss:  0.6655634045600891\n",
      "\n",
      "the to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were\n",
      "Epoch 1/30\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.7497 - accuracy: 0.5759WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0063s vs `on_test_batch_end` time: 0.0152s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 79ms/step - loss: 0.7486 - accuracy: 0.5781 - val_loss: 0.7018 - val_accuracy: 0.4889\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.7027 - accuracy: 0.5163 - val_loss: 0.6967 - val_accuracy: 0.4982\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.6949 - accuracy: 0.5437 - val_loss: 0.6925 - val_accuracy: 0.5562\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6948 - accuracy: 0.5625 - val_loss: 0.6897 - val_accuracy: 0.5770\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6868 - accuracy: 0.5956 - val_loss: 0.6874 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6843 - accuracy: 0.5950 - val_loss: 0.6842 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6758 - accuracy: 0.6100 - val_loss: 0.6833 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6840 - accuracy: 0.5775 - val_loss: 0.6802 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6752 - accuracy: 0.6019 - val_loss: 0.6797 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6826 - accuracy: 0.5556 - val_loss: 0.6790 - val_accuracy: 0.5823\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6784 - accuracy: 0.5763 - val_loss: 0.6757 - val_accuracy: 0.5778\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6761 - accuracy: 0.5731 - val_loss: 0.6768 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6741 - accuracy: 0.5850 - val_loss: 0.6735 - val_accuracy: 0.5786\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6777 - accuracy: 0.5731 - val_loss: 0.6767 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6791 - accuracy: 0.5656 - val_loss: 0.6724 - val_accuracy: 0.5665\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6678 - accuracy: 0.5962 - val_loss: 0.6774 - val_accuracy: 0.5794\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6839 - accuracy: 0.5469 - val_loss: 0.6713 - val_accuracy: 0.5628\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6790 - accuracy: 0.5625 - val_loss: 0.6715 - val_accuracy: 0.5783\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6701 - accuracy: 0.5925 - val_loss: 0.6706 - val_accuracy: 0.5662\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6773 - accuracy: 0.5650 - val_loss: 0.6700 - val_accuracy: 0.5675\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6695 - accuracy: 0.5850 - val_loss: 0.6728 - val_accuracy: 0.5810\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6743 - accuracy: 0.5844 - val_loss: 0.6709 - val_accuracy: 0.5744\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6812 - accuracy: 0.5681 - val_loss: 0.6698 - val_accuracy: 0.5862\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6737 - accuracy: 0.5700 - val_loss: 0.6690 - val_accuracy: 0.5754\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6716 - accuracy: 0.5781 - val_loss: 0.6709 - val_accuracy: 0.5831\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6731 - accuracy: 0.5581 - val_loss: 0.6685 - val_accuracy: 0.5746\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6688 - accuracy: 0.5894 - val_loss: 0.6685 - val_accuracy: 0.5696\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6692 - accuracy: 0.5956 - val_loss: 0.6698 - val_accuracy: 0.5849\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6602 - accuracy: 0.5925 - val_loss: 0.6714 - val_accuracy: 0.5741\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6622 - accuracy: 0.5894 - val_loss: 0.6772 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 6s - loss: 0.6263 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0076s vs `on_test_batch_end` time: 0.0149s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6706 - accuracy: 0.5877\n",
      "training acc:  0.5893750190734863 , training loss:  0.6621596813201904 , val acc:  0.5793776512145996 , val loss:  0.6772217154502869 , test acc:  0.5876677632331848 , test loss:  0.6705853939056396\n",
      "\n",
      "the to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.5199 - accuracy: 0.8125WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0077s vs `on_train_batch_end` time: 0.0132s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.7026 - accuracy: 0.5181 - val_loss: 0.6899 - val_accuracy: 0.5712\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6867 - accuracy: 0.6012 - val_loss: 0.6874 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6914 - accuracy: 0.5631 - val_loss: 0.6849 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6897 - accuracy: 0.5562 - val_loss: 0.6860 - val_accuracy: 0.5789\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6790 - accuracy: 0.5981 - val_loss: 0.6833 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6856 - accuracy: 0.5531 - val_loss: 0.6790 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6806 - accuracy: 0.5825 - val_loss: 0.6778 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6785 - accuracy: 0.5856 - val_loss: 0.6766 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6752 - accuracy: 0.5831 - val_loss: 0.6774 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6818 - accuracy: 0.5569 - val_loss: 0.6752 - val_accuracy: 0.5717\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6790 - accuracy: 0.5800 - val_loss: 0.6737 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6799 - accuracy: 0.5500 - val_loss: 0.6749 - val_accuracy: 0.5907\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6746 - accuracy: 0.5706 - val_loss: 0.6719 - val_accuracy: 0.5670\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6738 - accuracy: 0.5825 - val_loss: 0.6797 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6854 - accuracy: 0.5344 - val_loss: 0.6719 - val_accuracy: 0.5815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6689 - accuracy: 0.5700 - val_loss: 0.6762 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 7s - loss: 0.6239 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_test_batch_end` time: 0.0131s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6711 - accuracy: 0.5877\n",
      "training acc:  0.5699999928474426 , training loss:  0.6689412593841553 , val acc:  0.5793776512145996 , val loss:  0.6761950254440308 , test acc:  0.5876677632331848 , test loss:  0.6711481809616089\n",
      "\n",
      "the to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help around either best lot give etc always x form high note > means power above order less check list edit found must few bit solution having based start made trying % done end option doing least likely run field & key size \\mathcal word server keep small type 0 already\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6926 - accuracy: 0.5594 - val_loss: 0.6912 - val_accuracy: 0.5736\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6905 - accuracy: 0.5675 - val_loss: 0.6837 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6845 - accuracy: 0.5725 - val_loss: 0.6887 - val_accuracy: 0.5633\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6717 - accuracy: 0.6237 - val_loss: 0.6849 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6847 - accuracy: 0.5631 - val_loss: 0.6786 - val_accuracy: 0.5717\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6768 - accuracy: 0.5944 - val_loss: 0.6767 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6707 - accuracy: 0.5831 - val_loss: 0.6773 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6834 - accuracy: 0.5525 - val_loss: 0.6754 - val_accuracy: 0.5802\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6782 - accuracy: 0.5600 - val_loss: 0.6740 - val_accuracy: 0.5733\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6780 - accuracy: 0.5669 - val_loss: 0.6726 - val_accuracy: 0.5767\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6754 - accuracy: 0.5731 - val_loss: 0.6721 - val_accuracy: 0.5767\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6740 - accuracy: 0.5656 - val_loss: 0.6711 - val_accuracy: 0.5678\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6842 - accuracy: 0.5519 - val_loss: 0.6720 - val_accuracy: 0.5902\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6736 - accuracy: 0.5619 - val_loss: 0.6707 - val_accuracy: 0.5649\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6835 - accuracy: 0.5456 - val_loss: 0.6716 - val_accuracy: 0.5894\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6755 - accuracy: 0.5681 - val_loss: 0.6708 - val_accuracy: 0.5699\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6638 - accuracy: 0.6131 - val_loss: 0.6697 - val_accuracy: 0.5699\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6647 - accuracy: 0.5931 - val_loss: 0.6722 - val_accuracy: 0.5789\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6629 - accuracy: 0.6025 - val_loss: 0.6703 - val_accuracy: 0.5659\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6710 - accuracy: 0.5619 - val_loss: 0.6693 - val_accuracy: 0.5638\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6675 - accuracy: 0.5719 - val_loss: 0.6686 - val_accuracy: 0.5773\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6859 - accuracy: 0.5475 - val_loss: 0.6697 - val_accuracy: 0.5902\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6609 - accuracy: 0.6006 - val_loss: 0.6714 - val_accuracy: 0.5733\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6798 - accuracy: 0.5562 - val_loss: 0.6694 - val_accuracy: 0.5620\n",
      "  1/596 [..............................] - ETA: 7s - loss: 0.6648 - accuracy: 0.6875WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0075s vs `on_test_batch_end` time: 0.0118s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6642 - accuracy: 0.5767\n",
      "training acc:  0.5562499761581421 , training loss:  0.6797619462013245 , val acc:  0.5619725584983826 , val loss:  0.6693513989448547 , test acc:  0.5766568779945374 , test loss:  0.664152979850769\n",
      "\n",
      "the to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help around either best lot give etc always x form high note > means power above order less check list edit found must few bit solution having based start made trying % done end option doing least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct once day again similar looking light rather issue non us information person someone specific output reason single mean result space she name de times said simple open quite simply never level show process put years place real often\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7076 - accuracy: 0.5650WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_test_batch_end` time: 0.0065s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.7076 - accuracy: 0.5650 - val_loss: 0.6930 - val_accuracy: 0.5280\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6861 - accuracy: 0.5756 - val_loss: 0.6914 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6928 - accuracy: 0.5519 - val_loss: 0.6895 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6950 - accuracy: 0.5250 - val_loss: 0.6864 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6890 - accuracy: 0.5744 - val_loss: 0.6825 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6881 - accuracy: 0.5638 - val_loss: 0.6863 - val_accuracy: 0.5773\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6837 - accuracy: 0.5706 - val_loss: 0.6781 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6771 - accuracy: 0.5838 - val_loss: 0.6838 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6750 - accuracy: 0.6019 - val_loss: 0.6787 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6727 - accuracy: 0.5987 - val_loss: 0.6745 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6762 - accuracy: 0.5769 - val_loss: 0.6735 - val_accuracy: 0.5643\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6745 - accuracy: 0.5694 - val_loss: 0.6726 - val_accuracy: 0.5791\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6733 - accuracy: 0.5831 - val_loss: 0.6721 - val_accuracy: 0.5791\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6801 - accuracy: 0.5550 - val_loss: 0.6714 - val_accuracy: 0.5730\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6751 - accuracy: 0.5650 - val_loss: 0.6772 - val_accuracy: 0.5794\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6816 - accuracy: 0.5612 - val_loss: 0.6741 - val_accuracy: 0.5844\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.6801 - accuracy: 0.5494 - val_loss: 0.6699 - val_accuracy: 0.5636\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6684 - accuracy: 0.5788 - val_loss: 0.6705 - val_accuracy: 0.5730\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6607 - accuracy: 0.6187 - val_loss: 0.6719 - val_accuracy: 0.5794\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6683 - accuracy: 0.5681 - val_loss: 0.6685 - val_accuracy: 0.5696\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6606 - accuracy: 0.6094 - val_loss: 0.6696 - val_accuracy: 0.5654\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6769 - accuracy: 0.5494 - val_loss: 0.6687 - val_accuracy: 0.5928\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6742 - accuracy: 0.5675 - val_loss: 0.6711 - val_accuracy: 0.5878\n",
      "  1/596 [..............................] - ETA: 6s - loss: 0.7333 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0071s vs `on_test_batch_end` time: 0.0139s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6689 - accuracy: 0.5997\n",
      "training acc:  0.5674999952316284 , training loss:  0.6742269396781921 , val acc:  0.5878164768218994 , val loss:  0.6710597276687622 , test acc:  0.5997273325920105 , test loss:  0.6688575744628906\n",
      "\n",
      "the to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help around either best lot give etc always x form high note > means power above order less check list edit found must few bit solution having based start made trying % done end option doing least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct once day again similar looking light rather issue non us information person someone specific output reason single mean result space she name de times said simple open quite simply never level show process put years place real often usually input b understand site error below far last c world come group large under online working object fact que side course hard \\to makes method values layer important until him whether 5 next el original idea pretty got water called state amount current her color test tried y getting\n",
      "Epoch 1/30\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 0.7014 - accuracy: 0.5097WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0078s vs `on_test_batch_end` time: 0.0136s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.7012 - accuracy: 0.5100 - val_loss: 0.6815 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6853 - accuracy: 0.5669 - val_loss: 0.6800 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6830 - accuracy: 0.5663 - val_loss: 0.6778 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6788 - accuracy: 0.5850 - val_loss: 0.6768 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6778 - accuracy: 0.5675 - val_loss: 0.6751 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6707 - accuracy: 0.6075 - val_loss: 0.6751 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6765 - accuracy: 0.5738 - val_loss: 0.6733 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6567 - accuracy: 0.6200 - val_loss: 0.6836 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6752 - accuracy: 0.5800 - val_loss: 0.6802 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6804 - accuracy: 0.5594 - val_loss: 0.6735 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 7s - loss: 0.6325 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0201s). Check your callbacks.\n",
      "596/596 [==============================] - 15s 25ms/step - loss: 0.6691 - accuracy: 0.5877\n",
      "training acc:  0.559374988079071 , training loss:  0.6803648471832275 , val acc:  0.5793776512145996 , val loss:  0.6734700798988342 , test acc:  0.5876677632331848 , test loss:  0.6691117882728577\n",
      "\n",
      "the to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help around either best lot give etc always x form high note > means power above order less check list edit found must few bit solution having based start made trying % done end option doing least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct once day again similar looking light rather issue non us information person someone specific output reason single mean result space she name de times said simple open quite simply never level show process put years place real often usually input b understand site error below far last c world come group large under online working object fact que side course hard \\to makes method values layer important until him whether 5 next el original idea pretty got water called state amount current her color test tried y getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full itself old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.7369 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_train_batch_end` time: 0.0109s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6996 - accuracy: 0.5188 - val_loss: 0.6879 - val_accuracy: 0.5836\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6878 - accuracy: 0.5456 - val_loss: 0.6798 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.6819 - accuracy: 0.5644 - val_loss: 0.6835 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.6883 - accuracy: 0.5344 - val_loss: 0.6766 - val_accuracy: 0.5733\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6817 - accuracy: 0.5756 - val_loss: 0.6784 - val_accuracy: 0.5876\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6729 - accuracy: 0.5919 - val_loss: 0.6809 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6795 - accuracy: 0.5875 - val_loss: 0.6724 - val_accuracy: 0.5641\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6705 - accuracy: 0.5738 - val_loss: 0.6708 - val_accuracy: 0.5628\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6719 - accuracy: 0.5906 - val_loss: 0.6738 - val_accuracy: 0.5868\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6786 - accuracy: 0.5644 - val_loss: 0.6749 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6770 - accuracy: 0.5706 - val_loss: 0.6693 - val_accuracy: 0.5633\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6819 - accuracy: 0.5425 - val_loss: 0.6690 - val_accuracy: 0.5649\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6751 - accuracy: 0.5769 - val_loss: 0.6725 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6792 - accuracy: 0.5544 - val_loss: 0.6685 - val_accuracy: 0.5691\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6799 - accuracy: 0.5506 - val_loss: 0.6840 - val_accuracy: 0.5670\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6746 - accuracy: 0.5800 - val_loss: 0.6695 - val_accuracy: 0.5894\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6735 - accuracy: 0.5775 - val_loss: 0.6697 - val_accuracy: 0.5672\n",
      "  1/596 [..............................] - ETA: 7s - loss: 0.6532 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_test_batch_end` time: 0.0148s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6647 - accuracy: 0.5774\n",
      "training acc:  0.5774999856948853 , training loss:  0.6734520196914673 , val acc:  0.5672468543052673 , val loss:  0.6696746349334717 , test acc:  0.5773909687995911 , test loss:  0.6647463440895081\n",
      "\n",
      "the to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help around either best lot give etc always x form high note > means power above order less check list edit found must few bit solution having based start made trying % done end option doing least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct once day again similar looking light rather issue non us information person someone specific output reason single mean result space she name de times said simple open quite simply never level show process put years place real often usually input b understand site error below far last c world come group large under online working object fact que side course hard \\to makes method values layer important until him whether 5 next el original idea pretty got water called state amount current her color test tried y getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full itself old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away energy google comes book search changes write low anyone everything provide exactly yes ai easy experience making < thought wrong fine multiple product language hand standard n thanks several game perhaps ask tell design ' year nothing lower although uses feel\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6812 - accuracy: 0.5875WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_test_batch_end` time: 0.0113s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6812 - accuracy: 0.5875 - val_loss: 0.6855 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6846 - accuracy: 0.5769 - val_loss: 0.6805 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6862 - accuracy: 0.5556 - val_loss: 0.6817 - val_accuracy: 0.5934\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6814 - accuracy: 0.5719 - val_loss: 0.6779 - val_accuracy: 0.5636\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.6815 - accuracy: 0.5681 - val_loss: 0.6799 - val_accuracy: 0.5865\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6786 - accuracy: 0.5744 - val_loss: 0.6744 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6748 - accuracy: 0.5781 - val_loss: 0.6750 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6823 - accuracy: 0.5425 - val_loss: 0.6731 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6773 - accuracy: 0.5650 - val_loss: 0.6720 - val_accuracy: 0.5773\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6744 - accuracy: 0.5569 - val_loss: 0.6711 - val_accuracy: 0.5636\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6793 - accuracy: 0.5544 - val_loss: 0.6715 - val_accuracy: 0.5775\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6553 - accuracy: 0.6006 - val_loss: 0.6743 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6771 - accuracy: 0.5906 - val_loss: 0.6708 - val_accuracy: 0.5736\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6663 - accuracy: 0.5763 - val_loss: 0.6711 - val_accuracy: 0.5762\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6680 - accuracy: 0.5894 - val_loss: 0.6688 - val_accuracy: 0.5701\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.6740 - accuracy: 0.5700 - val_loss: 0.6688 - val_accuracy: 0.5852\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6818 - accuracy: 0.5450 - val_loss: 0.6766 - val_accuracy: 0.5802\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6733 - accuracy: 0.5669 - val_loss: 0.6683 - val_accuracy: 0.5649\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6731 - accuracy: 0.5631 - val_loss: 0.6681 - val_accuracy: 0.5691\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6846 - accuracy: 0.5462 - val_loss: 0.6689 - val_accuracy: 0.5944\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6806 - accuracy: 0.5619 - val_loss: 0.6680 - val_accuracy: 0.5709\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6653 - accuracy: 0.5800 - val_loss: 0.6716 - val_accuracy: 0.5757\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6651 - accuracy: 0.5875 - val_loss: 0.6687 - val_accuracy: 0.5649\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6753 - accuracy: 0.5506 - val_loss: 0.6674 - val_accuracy: 0.5791\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6765 - accuracy: 0.5437 - val_loss: 0.6696 - val_accuracy: 0.5876\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6738 - accuracy: 0.5756 - val_loss: 0.6688 - val_accuracy: 0.5886\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6830 - accuracy: 0.5356 - val_loss: 0.6673 - val_accuracy: 0.5839\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6577 - accuracy: 0.6031 - val_loss: 0.6706 - val_accuracy: 0.5662\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6707 - accuracy: 0.5750 - val_loss: 0.6697 - val_accuracy: 0.5636\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6686 - accuracy: 0.5713 - val_loss: 0.6671 - val_accuracy: 0.5791\n",
      "  1/596 [..............................] - ETA: 4s - loss: 0.6892 - accuracy: 0.6875WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_test_batch_end` time: 0.0152s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6627 - accuracy: 0.5929\n",
      "training acc:  0.5712500214576721 , training loss:  0.6686294674873352 , val acc:  0.5791139006614685 , val loss:  0.6670910120010376 , test acc:  0.5929110646247864 , test loss:  0.6627482175827026\n",
      "\n",
      "the to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help around either best lot give etc always x form high note > means power above order less check list edit found must few bit solution having based start made trying % done end option doing least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct once day again similar looking light rather issue non us information person someone specific output reason single mean result space she name de times said simple open quite simply never level show process put years place real often usually input b understand site error below far last c world come group large under online working object fact que side course hard \\to makes method values layer important until him whether 5 next el original idea pretty got water called state amount current her color test tried y getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full itself old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away energy google comes book search changes write low anyone everything provide exactly yes ai easy experience making < thought wrong fine multiple product language hand standard n thanks several game perhaps ask tell design ' year nothing lower although uses feel thus points update takes looks position useful added cases unless d true clear return lens _ content higher effect price believe en further almost view la model certain days string length files click context sentence others big against s normal gives step options turn english sort map terms close actual\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.6766 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0078s vs `on_train_batch_end` time: 0.0162s). Check your callbacks.\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.5950WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0064s vs `on_test_batch_end` time: 0.0153s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6875 - accuracy: 0.5950 - val_loss: 0.6881 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6726 - accuracy: 0.6250 - val_loss: 0.6881 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6928 - accuracy: 0.5481 - val_loss: 0.6972 - val_accuracy: 0.4892\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6802 - accuracy: 0.5856 - val_loss: 0.6826 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6878 - accuracy: 0.5581 - val_loss: 0.6817 - val_accuracy: 0.5881\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6852 - accuracy: 0.5425 - val_loss: 0.6802 - val_accuracy: 0.5873\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6867 - accuracy: 0.5450 - val_loss: 0.6809 - val_accuracy: 0.5862\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6683 - accuracy: 0.6012 - val_loss: 0.6928 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6825 - accuracy: 0.5669 - val_loss: 0.6737 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6771 - accuracy: 0.5781 - val_loss: 0.6729 - val_accuracy: 0.5786\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6687 - accuracy: 0.6069 - val_loss: 0.6719 - val_accuracy: 0.5736\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6803 - accuracy: 0.5475 - val_loss: 0.6711 - val_accuracy: 0.5701\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6623 - accuracy: 0.6100 - val_loss: 0.6723 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6558 - accuracy: 0.6256 - val_loss: 0.6785 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6714 - accuracy: 0.5838 - val_loss: 0.6756 - val_accuracy: 0.5794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/596 [..............................] - ETA: 4s - loss: 0.6260 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0064s vs `on_test_batch_end` time: 0.0127s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6701 - accuracy: 0.5877\n",
      "training acc:  0.5837500095367432 , training loss:  0.6713783740997314 , val acc:  0.5793776512145996 , val loss:  0.6756013631820679 , test acc:  0.5876677632331848 , test loss:  0.6700776219367981\n",
      "\n",
      "opt2\n",
      "opt2 ['/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/50word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/100word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/150word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/200word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/250word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/300word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/350word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/400word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/450word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt2/500word_list.txt']\n",
      "the . , to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 1.1368 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0266s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.7248 - accuracy: 0.4994 - val_loss: 0.6818 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6892 - accuracy: 0.5587 - val_loss: 0.6822 - val_accuracy: 0.5789\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6885 - accuracy: 0.5456 - val_loss: 0.6891 - val_accuracy: 0.5504\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6888 - accuracy: 0.5344 - val_loss: 0.6907 - val_accuracy: 0.5338\n",
      "  1/596 [..............................] - ETA: 6s - loss: 0.7297 - accuracy: 0.3125WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0179s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6924 - accuracy: 0.5218\n",
      "training acc:  0.534375011920929 , training loss:  0.6888455152511597 , val acc:  0.5337553024291992 , val loss:  0.6906894445419312 , test acc:  0.5218120813369751 , test loss:  0.6923706531524658\n",
      "\n",
      "the . , to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.8841 - accuracy: 0.3750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0075s vs `on_train_batch_end` time: 0.0139s). Check your callbacks.\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.6941 - accuracy: 0.5740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0064s vs `on_test_batch_end` time: 0.0153s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6945 - accuracy: 0.5725 - val_loss: 0.6881 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6930 - accuracy: 0.5794 - val_loss: 0.6879 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6903 - accuracy: 0.5700 - val_loss: 0.6837 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6910 - accuracy: 0.5519 - val_loss: 0.6843 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6784 - accuracy: 0.5994 - val_loss: 0.6870 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6836 - accuracy: 0.5881 - val_loss: 0.6800 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6843 - accuracy: 0.5656 - val_loss: 0.6784 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6848 - accuracy: 0.5481 - val_loss: 0.6776 - val_accuracy: 0.5789\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6742 - accuracy: 0.5931 - val_loss: 0.6794 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6854 - accuracy: 0.5525 - val_loss: 0.6755 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6811 - accuracy: 0.5612 - val_loss: 0.6772 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6742 - accuracy: 0.6044 - val_loss: 0.6767 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6769 - accuracy: 0.5694 - val_loss: 0.6732 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6708 - accuracy: 0.5831 - val_loss: 0.6756 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6833 - accuracy: 0.5544 - val_loss: 0.6731 - val_accuracy: 0.5794\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6736 - accuracy: 0.5731 - val_loss: 0.6737 - val_accuracy: 0.5839\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6785 - accuracy: 0.5931 - val_loss: 0.6739 - val_accuracy: 0.5794\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6610 - accuracy: 0.6225 - val_loss: 0.6732 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 6s - loss: 0.6298 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0073s vs `on_test_batch_end` time: 0.0188s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6697 - accuracy: 0.5877\n",
      "training acc:  0.6225000023841858 , training loss:  0.6609856486320496 , val acc:  0.5793776512145996 , val loss:  0.6731992363929749 , test acc:  0.5876677632331848 , test loss:  0.6696525812149048\n",
      "\n",
      "the . , to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between\n",
      "Epoch 1/30\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.7213 - accuracy: 0.5268WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0065s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.7213 - accuracy: 0.5256 - val_loss: 0.6822 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6873 - accuracy: 0.5587 - val_loss: 0.6805 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6767 - accuracy: 0.5987 - val_loss: 0.6788 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6851 - accuracy: 0.5537 - val_loss: 0.6778 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6833 - accuracy: 0.5688 - val_loss: 0.6796 - val_accuracy: 0.5804\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6828 - accuracy: 0.5706 - val_loss: 0.6849 - val_accuracy: 0.5686\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6870 - accuracy: 0.5419 - val_loss: 0.6753 - val_accuracy: 0.5791\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6823 - accuracy: 0.5625 - val_loss: 0.6765 - val_accuracy: 0.5765\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6757 - accuracy: 0.5750 - val_loss: 0.6735 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6681 - accuracy: 0.6106 - val_loss: 0.6747 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6815 - accuracy: 0.5644 - val_loss: 0.6779 - val_accuracy: 0.5802\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6786 - accuracy: 0.5769 - val_loss: 0.6728 - val_accuracy: 0.5789\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6784 - accuracy: 0.5612 - val_loss: 0.6718 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6684 - accuracy: 0.5975 - val_loss: 0.6709 - val_accuracy: 0.5791\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6703 - accuracy: 0.5800 - val_loss: 0.6700 - val_accuracy: 0.5643\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6794 - accuracy: 0.5550 - val_loss: 0.6696 - val_accuracy: 0.5593\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6814 - accuracy: 0.5575 - val_loss: 0.6695 - val_accuracy: 0.5712\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6632 - accuracy: 0.6050 - val_loss: 0.6718 - val_accuracy: 0.5794\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6652 - accuracy: 0.5931 - val_loss: 0.6717 - val_accuracy: 0.5794\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6679 - accuracy: 0.5763 - val_loss: 0.6693 - val_accuracy: 0.5767\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6722 - accuracy: 0.5850 - val_loss: 0.6678 - val_accuracy: 0.5691\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6591 - accuracy: 0.6094 - val_loss: 0.6755 - val_accuracy: 0.5794\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6850 - accuracy: 0.5519 - val_loss: 0.6691 - val_accuracy: 0.5749\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6634 - accuracy: 0.5994 - val_loss: 0.6691 - val_accuracy: 0.5854\n",
      "  1/596 [..............................] - ETA: 6s - loss: 0.7111 - accuracy: 0.3125WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_test_batch_end` time: 0.0113s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6681 - accuracy: 0.5964\n",
      "training acc:  0.5993750095367432 , training loss:  0.6633946895599365 , val acc:  0.5854430198669434 , val loss:  0.6691401600837708 , test acc:  0.5963716506958008 , test loss:  0.6681110262870789\n",
      "\n",
      "the . , to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part\n",
      "Epoch 1/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.6777 - accuracy: 0.6326WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0082s vs `on_test_batch_end` time: 0.0130s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6778 - accuracy: 0.6319 - val_loss: 0.6996 - val_accuracy: 0.5778\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6920 - accuracy: 0.5506 - val_loss: 0.6880 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6798 - accuracy: 0.6044 - val_loss: 0.6895 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6938 - accuracy: 0.5419 - val_loss: 0.6832 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6898 - accuracy: 0.5569 - val_loss: 0.6824 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6760 - accuracy: 0.6044 - val_loss: 0.6822 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6803 - accuracy: 0.5881 - val_loss: 0.6801 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6835 - accuracy: 0.5725 - val_loss: 0.6845 - val_accuracy: 0.5812\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6874 - accuracy: 0.5437 - val_loss: 0.6781 - val_accuracy: 0.5659\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6768 - accuracy: 0.5844 - val_loss: 0.6770 - val_accuracy: 0.5691\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6806 - accuracy: 0.5819 - val_loss: 0.6757 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6738 - accuracy: 0.5919 - val_loss: 0.6797 - val_accuracy: 0.5820\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6925 - accuracy: 0.5288 - val_loss: 0.6730 - val_accuracy: 0.5789\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6706 - accuracy: 0.6125 - val_loss: 0.7200 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6617 - accuracy: 0.6150 - val_loss: 0.6781 - val_accuracy: 0.5794\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6784 - accuracy: 0.5738 - val_loss: 0.6717 - val_accuracy: 0.5794\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.6858 - accuracy: 0.5494 - val_loss: 0.6701 - val_accuracy: 0.5614\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6730 - accuracy: 0.5894 - val_loss: 0.6697 - val_accuracy: 0.5596\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6659 - accuracy: 0.5656 - val_loss: 0.6696 - val_accuracy: 0.5831\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6705 - accuracy: 0.5875 - val_loss: 0.6888 - val_accuracy: 0.5794\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6751 - accuracy: 0.5744 - val_loss: 0.6705 - val_accuracy: 0.5854\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6816 - accuracy: 0.5556 - val_loss: 0.6759 - val_accuracy: 0.5794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/596 [..............................] - ETA: 6s - loss: 0.6208 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0076s vs `on_test_batch_end` time: 0.0172s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6710 - accuracy: 0.5877\n",
      "training acc:  0.5556250214576721 , training loss:  0.6815797686576843 , val acc:  0.5793776512145996 , val loss:  0.6758808493614197 , test acc:  0.5876677632331848 , test loss:  0.6709553599357605\n",
      "\n",
      "the . , to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help around either best lot give etc always x form high note > means power above order less check list edit found must few bit solution having based start made trying % done end option doing least likely run field & key size \\mathcal word server keep small type\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.9170 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_end` time: 0.0174s). Check your callbacks.\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.6978 - accuracy: 0.5606WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0063s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6977 - accuracy: 0.5606 - val_loss: 0.6936 - val_accuracy: 0.4974\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6886 - accuracy: 0.5956 - val_loss: 0.6877 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6925 - accuracy: 0.5362 - val_loss: 0.6999 - val_accuracy: 0.4288\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6870 - accuracy: 0.5669 - val_loss: 0.6858 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6861 - accuracy: 0.5806 - val_loss: 0.6828 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6753 - accuracy: 0.6069 - val_loss: 0.6821 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6903 - accuracy: 0.5456 - val_loss: 0.6819 - val_accuracy: 0.5667\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6777 - accuracy: 0.5994 - val_loss: 0.6824 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6653 - accuracy: 0.6275 - val_loss: 0.6826 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6913 - accuracy: 0.5337 - val_loss: 0.6767 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6794 - accuracy: 0.5625 - val_loss: 0.6755 - val_accuracy: 0.5791\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6742 - accuracy: 0.6031 - val_loss: 0.6748 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6808 - accuracy: 0.5562 - val_loss: 0.6747 - val_accuracy: 0.5657\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6848 - accuracy: 0.5400 - val_loss: 0.6730 - val_accuracy: 0.5791\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6818 - accuracy: 0.5406 - val_loss: 0.6790 - val_accuracy: 0.5804\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6743 - accuracy: 0.5900 - val_loss: 0.6751 - val_accuracy: 0.5794\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6722 - accuracy: 0.5869 - val_loss: 0.6719 - val_accuracy: 0.5794\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6682 - accuracy: 0.5913 - val_loss: 0.6710 - val_accuracy: 0.5651\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6820 - accuracy: 0.5406 - val_loss: 0.6761 - val_accuracy: 0.5849\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6833 - accuracy: 0.5512 - val_loss: 0.6718 - val_accuracy: 0.5873\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6730 - accuracy: 0.5919 - val_loss: 0.6698 - val_accuracy: 0.5583\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6747 - accuracy: 0.5531 - val_loss: 0.6716 - val_accuracy: 0.5794\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6745 - accuracy: 0.5575 - val_loss: 0.6692 - val_accuracy: 0.5583\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6831 - accuracy: 0.5550 - val_loss: 0.6695 - val_accuracy: 0.5665\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6759 - accuracy: 0.5456 - val_loss: 0.6688 - val_accuracy: 0.5651\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6764 - accuracy: 0.5688 - val_loss: 0.6685 - val_accuracy: 0.5654\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6747 - accuracy: 0.5788 - val_loss: 0.6683 - val_accuracy: 0.5694\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6860 - accuracy: 0.5531 - val_loss: 0.6697 - val_accuracy: 0.5733\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6708 - accuracy: 0.5569 - val_loss: 0.6700 - val_accuracy: 0.5873\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6697 - accuracy: 0.5969 - val_loss: 0.6758 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 6s - loss: 0.6253 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0077s vs `on_test_batch_end` time: 0.0132s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6702 - accuracy: 0.5877\n",
      "training acc:  0.596875011920929 , training loss:  0.6696552038192749 , val acc:  0.5793776512145996 , val loss:  0.6757703423500061 , test acc:  0.5876677632331848 , test loss:  0.6702116131782532\n",
      "\n",
      "the . , to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help around either best lot give etc always x form high note > means power above order less check list edit found must few bit solution having based start made trying % done end option doing least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct once day again similar looking light rather issue non us information person someone specific output reason single mean result space she name de times said simple open quite simply never level show process put years place\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.5869WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0069s vs `on_test_batch_end` time: 0.0142s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6898 - accuracy: 0.5869 - val_loss: 0.6885 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6953 - accuracy: 0.5163 - val_loss: 0.6861 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6909 - accuracy: 0.5456 - val_loss: 0.6857 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6877 - accuracy: 0.5612 - val_loss: 0.6874 - val_accuracy: 0.5854\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6760 - accuracy: 0.6169 - val_loss: 0.6826 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6866 - accuracy: 0.5800 - val_loss: 0.6796 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6858 - accuracy: 0.5562 - val_loss: 0.6787 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6787 - accuracy: 0.5775 - val_loss: 0.6794 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6844 - accuracy: 0.5700 - val_loss: 0.6777 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6886 - accuracy: 0.5437 - val_loss: 0.6752 - val_accuracy: 0.5757\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6803 - accuracy: 0.5681 - val_loss: 0.6795 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6746 - accuracy: 0.5819 - val_loss: 0.6741 - val_accuracy: 0.5601\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6798 - accuracy: 0.5625 - val_loss: 0.6773 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6810 - accuracy: 0.5638 - val_loss: 0.6723 - val_accuracy: 0.5585\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6744 - accuracy: 0.5825 - val_loss: 0.6722 - val_accuracy: 0.5791\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6557 - accuracy: 0.6294 - val_loss: 0.6750 - val_accuracy: 0.5794\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6731 - accuracy: 0.5775 - val_loss: 0.6701 - val_accuracy: 0.5757\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6845 - accuracy: 0.5325 - val_loss: 0.6694 - val_accuracy: 0.5625\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6773 - accuracy: 0.5412 - val_loss: 0.6740 - val_accuracy: 0.5847\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6549 - accuracy: 0.6206 - val_loss: 0.6800 - val_accuracy: 0.5794\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6786 - accuracy: 0.5725 - val_loss: 0.6683 - val_accuracy: 0.5815\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6721 - accuracy: 0.5612 - val_loss: 0.6694 - val_accuracy: 0.5886\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6664 - accuracy: 0.5856 - val_loss: 0.6757 - val_accuracy: 0.5794\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6690 - accuracy: 0.5756 - val_loss: 0.6719 - val_accuracy: 0.5854\n",
      "  1/596 [..............................] - ETA: 7s - loss: 0.7383 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_test_batch_end` time: 0.0149s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6712 - accuracy: 0.5950\n",
      "training acc:  0.5756250023841858 , training loss:  0.6690226793289185 , val acc:  0.5854430198669434 , val loss:  0.6719338893890381 , test acc:  0.595008373260498 , test loss:  0.6711689233779907\n",
      "\n",
      "the . , to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help around either best lot give etc always x form high note > means power above order less check list edit found must few bit solution having based start made trying % done end option doing least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct once day again similar looking light rather issue non us information person someone specific output reason single mean result space she name de times said simple open quite simply never level show process put years place real often usually input b understand site error below far last c world come group large under online working object fact que side course hard \\to makes method values layer important until him whether 5 next el original idea pretty got water called state amount current her color test tried\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7044 - accuracy: 0.5050WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0104s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.7044 - accuracy: 0.5050 - val_loss: 0.6966 - val_accuracy: 0.4206\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6969 - accuracy: 0.5375 - val_loss: 0.6877 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6786 - accuracy: 0.6062 - val_loss: 0.6913 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6969 - accuracy: 0.5238 - val_loss: 0.6825 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6850 - accuracy: 0.5619 - val_loss: 0.6809 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6810 - accuracy: 0.5806 - val_loss: 0.6784 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6641 - accuracy: 0.6313 - val_loss: 0.6814 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6829 - accuracy: 0.5619 - val_loss: 0.6897 - val_accuracy: 0.5475\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6778 - accuracy: 0.5750 - val_loss: 0.6748 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6791 - accuracy: 0.5856 - val_loss: 0.6741 - val_accuracy: 0.5657\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6832 - accuracy: 0.5631 - val_loss: 0.6722 - val_accuracy: 0.5730\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6786 - accuracy: 0.5731 - val_loss: 0.6724 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6763 - accuracy: 0.5813 - val_loss: 0.6727 - val_accuracy: 0.5794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6791 - accuracy: 0.5575 - val_loss: 0.6713 - val_accuracy: 0.5876\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6762 - accuracy: 0.5575 - val_loss: 0.6695 - val_accuracy: 0.5762\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6691 - accuracy: 0.5950 - val_loss: 0.6689 - val_accuracy: 0.5630\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.6782 - accuracy: 0.5663 - val_loss: 0.6714 - val_accuracy: 0.5794\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6776 - accuracy: 0.5562 - val_loss: 0.6700 - val_accuracy: 0.5791\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6592 - accuracy: 0.6250 - val_loss: 0.6711 - val_accuracy: 0.5865\n",
      "  1/596 [..............................] - ETA: 3s - loss: 0.7228 - accuracy: 0.2500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0074s vs `on_test_batch_end` time: 0.0132s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6704 - accuracy: 0.5991\n",
      "training acc:  0.625 , training loss:  0.6592226624488831 , val acc:  0.5864979028701782 , val loss:  0.6710985898971558 , test acc:  0.5990981459617615 , test loss:  0.6703534126281738\n",
      "\n",
      "the . , to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help around either best lot give etc always x form high note > means power above order less check list edit found must few bit solution having based start made trying % done end option doing least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct once day again similar looking light rather issue non us information person someone specific output reason single mean result space she name de times said simple open quite simply never level show process put years place real often usually input b understand site error below far last c world come group large under online working object fact que side course hard \\to makes method values layer important until him whether 5 next el original idea pretty got water called state amount current her color test tried y getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full itself old term 4 great running life range control class address particular god numbers camera three paper human within\n",
      "Epoch 1/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.6989 - accuracy: 0.5404WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0077s vs `on_test_batch_end` time: 0.0143s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.6990 - accuracy: 0.5400 - val_loss: 0.6862 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6851 - accuracy: 0.5594 - val_loss: 0.6843 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.6817 - accuracy: 0.5956 - val_loss: 0.6804 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6913 - accuracy: 0.5263 - val_loss: 0.6784 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6744 - accuracy: 0.6069 - val_loss: 0.6764 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6813 - accuracy: 0.5831 - val_loss: 0.6757 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6882 - accuracy: 0.5138 - val_loss: 0.6748 - val_accuracy: 0.5580\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6805 - accuracy: 0.5663 - val_loss: 0.6737 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6778 - accuracy: 0.5831 - val_loss: 0.6741 - val_accuracy: 0.5831\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6602 - accuracy: 0.6137 - val_loss: 0.6831 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6778 - accuracy: 0.5638 - val_loss: 0.6777 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 6s - loss: 0.6146 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_test_batch_end` time: 0.0197s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6733 - accuracy: 0.5877\n",
      "training acc:  0.5637500286102295 , training loss:  0.6778134107589722 , val acc:  0.5793776512145996 , val loss:  0.6776947975158691 , test acc:  0.5876677632331848 , test loss:  0.6733382940292358\n",
      "\n",
      "the . , to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help around either best lot give etc always x form high note > means power above order less check list edit found must few bit solution having based start made trying % done end option doing least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct once day again similar looking light rather issue non us information person someone specific output reason single mean result space she name de times said simple open quite simply never level show process put years place real often usually input b understand site error below far last c world come group large under online working object fact que side course hard \\to makes method values layer important until him whether 5 next el original idea pretty got water called state amount current her color test tried y getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full itself old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away energy google comes book search changes write low anyone everything provide exactly yes ai easy experience making < thought wrong fine multiple product language hand standard n thanks several game perhaps ask tell design ' year nothing lower although\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.6993 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0067s vs `on_train_batch_end` time: 0.0104s). Check your callbacks.\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.6853 - accuracy: 0.5682WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0063s vs `on_test_batch_end` time: 0.0147s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6854 - accuracy: 0.5675 - val_loss: 0.6885 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6893 - accuracy: 0.5694 - val_loss: 0.6827 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6836 - accuracy: 0.5831 - val_loss: 0.6805 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6705 - accuracy: 0.6206 - val_loss: 0.6813 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6850 - accuracy: 0.5625 - val_loss: 0.6779 - val_accuracy: 0.5767\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6844 - accuracy: 0.5512 - val_loss: 0.6765 - val_accuracy: 0.5680\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6755 - accuracy: 0.5894 - val_loss: 0.6747 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6772 - accuracy: 0.5781 - val_loss: 0.6737 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6628 - accuracy: 0.6256 - val_loss: 0.6748 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6717 - accuracy: 0.5913 - val_loss: 0.6724 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6755 - accuracy: 0.5738 - val_loss: 0.6742 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6764 - accuracy: 0.5800 - val_loss: 0.6733 - val_accuracy: 0.5876\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6753 - accuracy: 0.5644 - val_loss: 0.6698 - val_accuracy: 0.5646\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6579 - accuracy: 0.6119 - val_loss: 0.6691 - val_accuracy: 0.5657\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6662 - accuracy: 0.5825 - val_loss: 0.6679 - val_accuracy: 0.5662\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6733 - accuracy: 0.5863 - val_loss: 0.6836 - val_accuracy: 0.5794\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6740 - accuracy: 0.5888 - val_loss: 0.6685 - val_accuracy: 0.5907\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6721 - accuracy: 0.5600 - val_loss: 0.6683 - val_accuracy: 0.5617\n",
      "  1/596 [..............................] - ETA: 10s - loss: 0.6572 - accuracy: 0.6875WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_test_batch_end` time: 0.0144s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6646 - accuracy: 0.5707\n",
      "training acc:  0.5600000023841858 , training loss:  0.6721343398094177 , val acc:  0.5617088675498962 , val loss:  0.6683036684989929 , test acc:  0.5706795454025269 , test loss:  0.664603590965271\n",
      "\n",
      "the . , to a  of and is i in you that it $ for   this be with as on are have if not can or but your 's n't would an do so from there will at by they   one my which what all more we some when then like was use / has just any also about get no how only could other time out does them than up need should way using same make want 'm their where work - because here see first two very into think even know these me 1 example may each people = different most used might much something now question 've he such am after well case its 're set good however number 2 been find try new problem say being since really many take both still possible data did answer those right another code who too between why were while over go had point change without value probably things page + better before image let ca sure create add back url$ enough actually 'd look 'll through system our his 3 function able down file every going long following given    own seems second off thing part though help around either best lot give etc always x form high note > means power above order less check list edit found must few bit solution having based start made trying % done end option doing least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct once day again similar looking light rather issue non us information person someone specific output reason single mean result space she name de times said simple open quite simply never level show process put years place real often usually input b understand site error below far last c world come group large under online working object fact que side course hard \\to makes method values layer important until him whether 5 next el original idea pretty got water called state amount current her color test tried y getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full itself old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away energy google comes book search changes write low anyone everything provide exactly yes ai easy experience making < thought wrong fine multiple product language hand standard n thanks several game perhaps ask tell design ' year nothing lower although uses feel thus points update takes looks position useful added cases unless d true clear return lens _ content higher effect price believe en further almost view la model certain days string length files click context sentence others big against s normal gives step options turn english sort map terms\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.6584 - accuracy: 0.6875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0074s vs `on_train_batch_end` time: 0.0122s). Check your callbacks.\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.6970 - accuracy: 0.5198WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0063s vs `on_test_batch_end` time: 0.0158s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6967 - accuracy: 0.5213 - val_loss: 0.6843 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6898 - accuracy: 0.5612 - val_loss: 0.6860 - val_accuracy: 0.5878\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6858 - accuracy: 0.5663 - val_loss: 0.6804 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6855 - accuracy: 0.5550 - val_loss: 0.6807 - val_accuracy: 0.5646\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6838 - accuracy: 0.5700 - val_loss: 0.6829 - val_accuracy: 0.5862\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6706 - accuracy: 0.6100 - val_loss: 0.6811 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 4s - loss: 0.6089 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_test_batch_end` time: 0.0186s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6774 - accuracy: 0.5877\n",
      "training acc:  0.6100000143051147 , training loss:  0.6705565452575684 , val acc:  0.5793776512145996 , val loss:  0.6811233758926392 , test acc:  0.5876677632331848 , test loss:  0.6773860454559326\n",
      "\n",
      "opt3\n",
      "opt3 ['/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/50word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/100word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/150word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/200word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/250word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/300word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/350word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/400word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/450word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt3/500word_list.txt']\n",
      " $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.6887 - accuracy: 0.5758WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0074s vs `on_test_batch_end` time: 0.0138s). Check your callbacks.\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6880 - accuracy: 0.5775 - val_loss: 0.6836 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6856 - accuracy: 0.5944 - val_loss: 0.6823 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6833 - accuracy: 0.5775 - val_loss: 0.6816 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6841 - accuracy: 0.5769 - val_loss: 0.6811 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6892 - accuracy: 0.5469 - val_loss: 0.6808 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6926 - accuracy: 0.5412 - val_loss: 0.6841 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6813 - accuracy: 0.5863 - val_loss: 0.6807 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6652 - accuracy: 0.6250 - val_loss: 0.6829 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6848 - accuracy: 0.5688 - val_loss: 0.6833 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6809 - accuracy: 0.5863 - val_loss: 0.6806 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 0.6783 - accuracy: 0.5881 - val_loss: 0.6807 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6879 - accuracy: 0.5400 - val_loss: 0.6806 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6819 - accuracy: 0.5763 - val_loss: 0.6852 - val_accuracy: 0.5488\n",
      "  1/596 [..............................] - ETA: 3s - loss: 0.6553 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_test_batch_end` time: 0.0143s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 23ms/step - loss: 0.6852 - accuracy: 0.5544\n",
      "training acc:  0.5762500166893005 , training loss:  0.681882381439209 , val acc:  0.5487869381904602 , val loss:  0.6852102279663086 , test acc:  0.5544253587722778 , test loss:  0.6851877570152283\n",
      "\n",
      " $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.6463 - accuracy: 0.6875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0074s vs `on_train_batch_end` time: 0.0146s). Check your callbacks.\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6862 - accuracy: 0.5719WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_test_batch_end` time: 0.0151s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6862 - accuracy: 0.5719 - val_loss: 0.6823 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6850 - accuracy: 0.5594 - val_loss: 0.6816 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6972 - accuracy: 0.5194 - val_loss: 0.6843 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6870 - accuracy: 0.5681 - val_loss: 0.6819 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6802 - accuracy: 0.5863 - val_loss: 0.6803 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6823 - accuracy: 0.5756 - val_loss: 0.6815 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6859 - accuracy: 0.5700 - val_loss: 0.6805 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6720 - accuracy: 0.6187 - val_loss: 0.6802 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6847 - accuracy: 0.5675 - val_loss: 0.6795 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6875 - accuracy: 0.5688 - val_loss: 0.6793 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6701 - accuracy: 0.6044 - val_loss: 0.6799 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6861 - accuracy: 0.5644 - val_loss: 0.6788 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6836 - accuracy: 0.5750 - val_loss: 0.6793 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6900 - accuracy: 0.5431 - val_loss: 0.6811 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6880 - accuracy: 0.5462 - val_loss: 0.6810 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 3s - loss: 0.6522 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0074s vs `on_test_batch_end` time: 0.0144s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 23ms/step - loss: 0.6796 - accuracy: 0.5877\n",
      "training acc:  0.5462499856948853 , training loss:  0.6879553198814392 , val acc:  0.5793776512145996 , val loss:  0.6810436248779297 , test acc:  0.5876677632331848 , test loss:  0.6795989274978638\n",
      "\n",
      " $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.8183 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0075s vs `on_train_batch_end` time: 0.0128s). Check your callbacks.\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.8439 - accuracy: 0.5038WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0071s vs `on_test_batch_end` time: 0.0129s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.8425 - accuracy: 0.5038 - val_loss: 0.6921 - val_accuracy: 0.5353\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.7019 - accuracy: 0.5238 - val_loss: 0.6840 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6773 - accuracy: 0.5987 - val_loss: 0.6823 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6734 - accuracy: 0.6100 - val_loss: 0.6811 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6708 - accuracy: 0.6081 - val_loss: 0.6820 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6794 - accuracy: 0.5906 - val_loss: 0.6810 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6915 - accuracy: 0.5344 - val_loss: 0.6818 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6809 - accuracy: 0.5850 - val_loss: 0.6794 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6924 - accuracy: 0.5325 - val_loss: 0.6791 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6876 - accuracy: 0.5600 - val_loss: 0.6787 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6880 - accuracy: 0.5569 - val_loss: 0.6784 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6826 - accuracy: 0.5756 - val_loss: 0.6785 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6752 - accuracy: 0.5975 - val_loss: 0.6795 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6795 - accuracy: 0.5856 - val_loss: 0.6783 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6850 - accuracy: 0.5650 - val_loss: 0.6789 - val_accuracy: 0.5794\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6896 - accuracy: 0.5500 - val_loss: 0.6815 - val_accuracy: 0.5794\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6889 - accuracy: 0.5437 - val_loss: 0.6793 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 3s - loss: 0.6447 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_test_batch_end` time: 0.0122s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6775 - accuracy: 0.5877\n",
      "training acc:  0.543749988079071 , training loss:  0.6889297366142273 , val acc:  0.5793776512145996 , val loss:  0.6793195605278015 , test acc:  0.5876677632331848 , test loss:  0.6774776577949524\n",
      "\n",
      " $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.5500 - accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0067s vs `on_train_batch_end` time: 0.0150s). Check your callbacks.\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.7108 - accuracy: 0.5619WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0065s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.7096 - accuracy: 0.5656 - val_loss: 0.6813 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6788 - accuracy: 0.5900 - val_loss: 0.6803 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6920 - accuracy: 0.5375 - val_loss: 0.6828 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6785 - accuracy: 0.5900 - val_loss: 0.6800 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6699 - accuracy: 0.6012 - val_loss: 0.6819 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6795 - accuracy: 0.5962 - val_loss: 0.6797 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6799 - accuracy: 0.5869 - val_loss: 0.6807 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6797 - accuracy: 0.5962 - val_loss: 0.6802 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6810 - accuracy: 0.5763 - val_loss: 0.6799 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 3s - loss: 0.6188 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0083s vs `on_test_batch_end` time: 0.0137s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 23ms/step - loss: 0.6765 - accuracy: 0.5877\n",
      "training acc:  0.5762500166893005 , training loss:  0.6810106039047241 , val acc:  0.5793776512145996 , val loss:  0.6799261569976807 , test acc:  0.5876677632331848 , test loss:  0.6764832139015198\n",
      "\n",
      " $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input b understand site error far last c world come group large online working object fact que side course hard \\to makes method values layer important whether 5 next el original idea pretty got water called state amount current color test tried getting 10 assume    free kind common    bytes\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.5381 - accuracy: 0.8125WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0200s). Check your callbacks.\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6805 - accuracy: 0.5412WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0064s vs `on_test_batch_end` time: 0.0144s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6805 - accuracy: 0.5412 - val_loss: 0.6836 - val_accuracy: 0.4997\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6834 - accuracy: 0.4975 - val_loss: 0.6820 - val_accuracy: 0.6015\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6817 - accuracy: 0.6144 - val_loss: 0.6806 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6783 - accuracy: 0.5975 - val_loss: 0.6794 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6764 - accuracy: 0.5781 - val_loss: 0.6788 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6933 - accuracy: 0.5381 - val_loss: 0.6807 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6766 - accuracy: 0.6131 - val_loss: 0.6780 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6778 - accuracy: 0.6087 - val_loss: 0.6770 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6733 - accuracy: 0.6069 - val_loss: 0.6763 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6676 - accuracy: 0.6131 - val_loss: 0.6756 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6919 - accuracy: 0.5269 - val_loss: 0.6773 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6703 - accuracy: 0.6106 - val_loss: 0.6749 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6667 - accuracy: 0.5994 - val_loss: 0.6752 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6746 - accuracy: 0.5788 - val_loss: 0.6741 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6791 - accuracy: 0.5656 - val_loss: 0.6749 - val_accuracy: 0.5794\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6702 - accuracy: 0.5719 - val_loss: 0.6736 - val_accuracy: 0.5794\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6740 - accuracy: 0.5531 - val_loss: 0.6739 - val_accuracy: 0.5794\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6689 - accuracy: 0.5838 - val_loss: 0.6734 - val_accuracy: 0.5794\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6656 - accuracy: 0.6131 - val_loss: 0.6735 - val_accuracy: 0.5794\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6804 - accuracy: 0.5500 - val_loss: 0.6729 - val_accuracy: 0.5794\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6784 - accuracy: 0.5781 - val_loss: 0.6729 - val_accuracy: 0.5794\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6722 - accuracy: 0.5800 - val_loss: 0.6722 - val_accuracy: 0.5794\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6770 - accuracy: 0.5581 - val_loss: 0.6727 - val_accuracy: 0.5794\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6719 - accuracy: 0.5956 - val_loss: 0.6730 - val_accuracy: 0.5794\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6885 - accuracy: 0.5387 - val_loss: 0.6741 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 4s - loss: 0.6821 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_test_batch_end` time: 0.0131s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 23ms/step - loss: 0.6720 - accuracy: 0.5877\n",
      "training acc:  0.5387499928474426 , training loss:  0.6885057091712952 , val acc:  0.5793776512145996 , val loss:  0.6741366386413574 , test acc:  0.5876677632331848 , test loss:  0.6720059514045715\n",
      "\n",
      " $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input b understand site error far last c world come group large online working object fact que side course hard \\to makes method values layer important whether 5 next el original idea pretty got water called state amount current color test tried getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.7364 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0150s). Check your callbacks.\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6766 - accuracy: 0.5819WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0073s vs `on_test_batch_end` time: 0.0130s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6766 - accuracy: 0.5819 - val_loss: 0.6848 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6773 - accuracy: 0.5944 - val_loss: 0.6839 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6788 - accuracy: 0.5950 - val_loss: 0.6803 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6723 - accuracy: 0.6012 - val_loss: 0.6796 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6797 - accuracy: 0.5806 - val_loss: 0.6787 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6794 - accuracy: 0.5850 - val_loss: 0.6785 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6736 - accuracy: 0.5900 - val_loss: 0.6783 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6886 - accuracy: 0.5506 - val_loss: 0.6793 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6838 - accuracy: 0.5688 - val_loss: 0.6780 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6700 - accuracy: 0.6081 - val_loss: 0.6763 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6659 - accuracy: 0.6025 - val_loss: 0.6767 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6676 - accuracy: 0.5900 - val_loss: 0.6764 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6568 - accuracy: 0.6237 - val_loss: 0.6794 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 3s - loss: 0.6359 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_test_batch_end` time: 0.0189s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6761 - accuracy: 0.5877\n",
      "training acc:  0.6237499713897705 , training loss:  0.6568083763122559 , val acc:  0.5793776512145996 , val loss:  0.6793557405471802 , test acc:  0.5876677632331848 , test loss:  0.6760610342025757\n",
      "\n",
      " $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input b understand site error far last c world come group large online working object fact que side course hard \\to makes method values layer important whether 5 next el original idea pretty got water called state amount current color test tried getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away energy google comes book search changes write low anyone everything provide exactly yes ai easy experience making < thought wrong fine multiple product language hand standard n thanks several game perhaps ask tell design ' year nothing lower although uses feel thus points update takes looks position useful added cases\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.5605 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0063s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.7124 - accuracy: 0.4956 - val_loss: 0.6852 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6771 - accuracy: 0.5981 - val_loss: 0.6818 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6885 - accuracy: 0.5587 - val_loss: 0.6819 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6898 - accuracy: 0.5400 - val_loss: 0.6847 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6841 - accuracy: 0.5813 - val_loss: 0.6810 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6819 - accuracy: 0.5688 - val_loss: 0.6803 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6868 - accuracy: 0.5738 - val_loss: 0.6799 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6674 - accuracy: 0.6162 - val_loss: 0.6816 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6853 - accuracy: 0.5731 - val_loss: 0.6797 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6843 - accuracy: 0.5719 - val_loss: 0.6797 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6757 - accuracy: 0.5900 - val_loss: 0.6797 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6778 - accuracy: 0.5925 - val_loss: 0.6796 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6828 - accuracy: 0.5706 - val_loss: 0.6796 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6715 - accuracy: 0.6100 - val_loss: 0.6817 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6515 - accuracy: 0.6406 - val_loss: 0.6869 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 0s - loss: 0.6021 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_test_batch_end` time: 0.0138s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 23ms/step - loss: 0.6824 - accuracy: 0.5877\n",
      "training acc:  0.640625 , training loss:  0.6514719128608704 , val acc:  0.5793776512145996 , val loss:  0.6869338750839233 , test acc:  0.5876677632331848 , test loss:  0.6824226379394531\n",
      "\n",
      " $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input b understand site error far last c world come group large online working object fact que side course hard \\to makes method values layer important whether 5 next el original idea pretty got water called state amount current color test tried getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away energy google comes book search changes write low anyone everything provide exactly yes ai easy experience making < thought wrong fine multiple product language hand standard n thanks several game perhaps ask tell design ' year nothing lower although uses feel thus points update takes looks position useful added cases unless true clear return lens _ content higher effect price believe en almost view la model certain days string length files click context sentence others big normal gives step options turn english sort map terms close actual future seen link avoid allow network per problems easily \\\\ 100 meaning main\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6834 - accuracy: 0.5763 - val_loss: 0.6829 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6804 - accuracy: 0.5794 - val_loss: 0.6820 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6870 - accuracy: 0.5487 - val_loss: 0.6820 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6811 - accuracy: 0.5738 - val_loss: 0.6818 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6798 - accuracy: 0.5981 - val_loss: 0.6820 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6886 - accuracy: 0.5644 - val_loss: 0.6833 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6909 - accuracy: 0.5506 - val_loss: 0.6831 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 7s - loss: 0.6559 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0073s vs `on_test_batch_end` time: 0.0134s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 23ms/step - loss: 0.6816 - accuracy: 0.5877\n",
      "training acc:  0.5506250262260437 , training loss:  0.6909430623054504 , val acc:  0.5793776512145996 , val loss:  0.6831066012382507 , test acc:  0.5876677632331848 , test loss:  0.6815735697746277\n",
      "\n",
      " $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input b understand site error far last c world come group large online working object fact que side course hard \\to makes method values layer important whether 5 next el original idea pretty got water called state amount current color test tried getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away energy google comes book search changes write low anyone everything provide exactly yes ai easy experience making < thought wrong fine multiple product language hand standard n thanks several game perhaps ask tell design ' year nothing lower although uses feel thus points update takes looks position useful added cases unless true clear return lens _ content higher effect price believe en almost view la model certain days string length files click context sentence others big normal gives step options turn english sort map terms close actual future seen link avoid allow network per problems easily \\\\ 100 meaning main client computer known smaller tool difficult please research save whole generally setting bad mind transaction functions choose sometimes therefore sound ones related instance   characters along play images mode move database cause rate gets support yet table e says background examples web money head reading random inside n$ rules happen\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.7981 - accuracy: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0074s vs `on_train_batch_end` time: 0.0148s). Check your callbacks.\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6954 - accuracy: 0.5219 - val_loss: 0.6818 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6863 - accuracy: 0.5656 - val_loss: 0.6819 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6706 - accuracy: 0.5894 - val_loss: 0.6818 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6853 - accuracy: 0.5713 - val_loss: 0.6803 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6735 - accuracy: 0.6125 - val_loss: 0.6804 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6883 - accuracy: 0.5587 - val_loss: 0.6805 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6790 - accuracy: 0.5756 - val_loss: 0.6797 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6758 - accuracy: 0.5806 - val_loss: 0.6802 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6721 - accuracy: 0.5788 - val_loss: 0.6804 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6642 - accuracy: 0.6250 - val_loss: 0.6836 - val_accuracy: 0.5794\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6797 - accuracy: 0.5877\n",
      "training acc:  0.625 , training loss:  0.6642093062400818 , val acc:  0.5793776512145996 , val loss:  0.6836363673210144 , test acc:  0.5876677632331848 , test loss:  0.679703414440155\n",
      "\n",
      " $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input b understand site error far last c world come group large online working object fact que side course hard \\to makes method values layer important whether 5 next el original idea pretty got water called state amount current color test tried getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away energy google comes book search changes write low anyone everything provide exactly yes ai easy experience making < thought wrong fine multiple product language hand standard n thanks several game perhaps ask tell design ' year nothing lower although uses feel thus points update takes looks position useful added cases unless true clear return lens _ content higher effect price believe en almost view la model certain days string length files click context sentence others big normal gives step options turn english sort map terms close actual future seen link avoid allow network per problems easily \\\\ 100 meaning main client computer known smaller tool difficult please research save whole generally setting bad mind transaction functions choose sometimes therefore sound ones related instance   characters along play images mode move database cause rate gets support yet table e says background examples web money head reading random inside n$ rules happen taking guess approach mm pages hope via 6 depends explanation photoshop assuming build default become company application air users windows body apply bitcoin later directly writing custom target program rule situation story structure exact parts local stop longer remove algorithm sequence limit service history job larger whatever half theory base\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.8195 - accuracy: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_train_batch_end` time: 0.0113s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6890 - accuracy: 0.5400 - val_loss: 0.6827 - val_accuracy: 0.5941\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6861 - accuracy: 0.5556 - val_loss: 0.6827 - val_accuracy: 0.6057\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6792 - accuracy: 0.5794 - val_loss: 0.6815 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6855 - accuracy: 0.5819 - val_loss: 0.6809 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6782 - accuracy: 0.5919 - val_loss: 0.6797 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6831 - accuracy: 0.5925 - val_loss: 0.6806 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6719 - accuracy: 0.6212 - val_loss: 0.6779 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6846 - accuracy: 0.5519 - val_loss: 0.6807 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6874 - accuracy: 0.5394 - val_loss: 0.6805 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6815 - accuracy: 0.5806 - val_loss: 0.6778 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6755 - accuracy: 0.6119 - val_loss: 0.6773 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6764 - accuracy: 0.5975 - val_loss: 0.6766 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6690 - accuracy: 0.6100 - val_loss: 0.6758 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6668 - accuracy: 0.6288 - val_loss: 0.6772 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6743 - accuracy: 0.5981 - val_loss: 0.6764 - val_accuracy: 0.5794\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6780 - accuracy: 0.5744 - val_loss: 0.6755 - val_accuracy: 0.5794\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6892 - accuracy: 0.5319 - val_loss: 0.6789 - val_accuracy: 0.5794\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6759 - accuracy: 0.5756 - val_loss: 0.6748 - val_accuracy: 0.5794\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6844 - accuracy: 0.5512 - val_loss: 0.6786 - val_accuracy: 0.5794\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6757 - accuracy: 0.5906 - val_loss: 0.6750 - val_accuracy: 0.5794\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6707 - accuracy: 0.5913 - val_loss: 0.6747 - val_accuracy: 0.5794\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6807 - accuracy: 0.5744 - val_loss: 0.6749 - val_accuracy: 0.5794\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6834 - accuracy: 0.5362 - val_loss: 0.6783 - val_accuracy: 0.5794\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6765 - accuracy: 0.5813 - val_loss: 0.6742 - val_accuracy: 0.5794\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6724 - accuracy: 0.5956 - val_loss: 0.6748 - val_accuracy: 0.5794\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6735 - accuracy: 0.6031 - val_loss: 0.6747 - val_accuracy: 0.5794\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6747 - accuracy: 0.5756 - val_loss: 0.6737 - val_accuracy: 0.5794\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6716 - accuracy: 0.5906 - val_loss: 0.6735 - val_accuracy: 0.5794\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6787 - accuracy: 0.5813 - val_loss: 0.6736 - val_accuracy: 0.5794\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6696 - accuracy: 0.5894 - val_loss: 0.6735 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 4s - loss: 0.6473 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0182s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6706 - accuracy: 0.5877\n",
      "training acc:  0.5893750190734863 , training loss:  0.6695723533630371 , val acc:  0.5793776512145996 , val loss:  0.6735157370567322 , test acc:  0.5876677632331848 , test loss:  0.6706048846244812\n",
      "\n",
      "opt4\n",
      "opt4 ['/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/50word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/100word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/150word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/200word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/250word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/300word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/350word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/400word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/450word_list.txt', '/home/sukanya/PycharmProjects/SiameseNNPAN/src/word_index/opt4/500word_list.txt']\n",
      ". ,  $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6953 - accuracy: 0.5450 - val_loss: 0.6891 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6905 - accuracy: 0.5550 - val_loss: 0.6838 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6891 - accuracy: 0.5725 - val_loss: 0.6862 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6862 - accuracy: 0.5569 - val_loss: 0.6829 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6918 - accuracy: 0.5387 - val_loss: 0.6963 - val_accuracy: 0.5011\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6899 - accuracy: 0.5475 - val_loss: 0.6986 - val_accuracy: 0.4924\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6847 - accuracy: 0.5650 - val_loss: 0.6826 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6831 - accuracy: 0.5825 - val_loss: 0.6847 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6714 - accuracy: 0.6131 - val_loss: 0.6814 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6766 - accuracy: 0.6069 - val_loss: 0.6803 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6842 - accuracy: 0.5763 - val_loss: 0.6802 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6866 - accuracy: 0.5650 - val_loss: 0.6795 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6749 - accuracy: 0.6062 - val_loss: 0.6793 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6879 - accuracy: 0.5462 - val_loss: 0.6791 - val_accuracy: 0.5794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6758 - accuracy: 0.6075 - val_loss: 0.6794 - val_accuracy: 0.5794\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6882 - accuracy: 0.5375 - val_loss: 0.6822 - val_accuracy: 0.5538\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6873 - accuracy: 0.5575 - val_loss: 0.6787 - val_accuracy: 0.5794\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6820 - accuracy: 0.5869 - val_loss: 0.6799 - val_accuracy: 0.5794\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6849 - accuracy: 0.5850 - val_loss: 0.6797 - val_accuracy: 0.5794\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6784 - accuracy: 0.5769 - val_loss: 0.6834 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 3s - loss: 0.6042 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0075s vs `on_test_batch_end` time: 0.0135s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 23ms/step - loss: 0.6795 - accuracy: 0.5877\n",
      "training acc:  0.5768749713897705 , training loss:  0.678435206413269 , val acc:  0.5793776512145996 , val loss:  0.6834168434143066 , test acc:  0.5876677632331848 , test loss:  0.6795275211334229\n",
      "\n",
      ". ,  $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.4796 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0168s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.7041 - accuracy: 0.5138 - val_loss: 0.6843 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6904 - accuracy: 0.5612 - val_loss: 0.6841 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6847 - accuracy: 0.5938 - val_loss: 0.6827 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6867 - accuracy: 0.5688 - val_loss: 0.6824 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 0.6680 - accuracy: 0.6281 - val_loss: 0.6955 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6842 - accuracy: 0.5813 - val_loss: 0.6807 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6819 - accuracy: 0.5713 - val_loss: 0.6811 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 0.6775 - accuracy: 0.5931 - val_loss: 0.6797 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6732 - accuracy: 0.6100 - val_loss: 0.6842 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6854 - accuracy: 0.5681 - val_loss: 0.6805 - val_accuracy: 0.5791\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6785 - accuracy: 0.5962 - val_loss: 0.6788 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6825 - accuracy: 0.5587 - val_loss: 0.6783 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6736 - accuracy: 0.6056 - val_loss: 0.6787 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6752 - accuracy: 0.5987 - val_loss: 0.6822 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6714 - accuracy: 0.6056 - val_loss: 0.6784 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 7s - loss: 0.6265 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_test_batch_end` time: 0.0204s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6754 - accuracy: 0.5877\n",
      "training acc:  0.6056249737739563 , training loss:  0.6714061498641968 , val acc:  0.5793776512145996 , val loss:  0.6783866286277771 , test acc:  0.5876677632331848 , test loss:  0.6753596663475037\n",
      "\n",
      ". ,  $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6803 - accuracy: 0.6125 - val_loss: 0.6862 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6865 - accuracy: 0.5863 - val_loss: 0.6847 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6835 - accuracy: 0.5888 - val_loss: 0.6834 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6888 - accuracy: 0.5681 - val_loss: 0.6823 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6895 - accuracy: 0.5669 - val_loss: 0.6808 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6701 - accuracy: 0.6156 - val_loss: 0.6820 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6804 - accuracy: 0.5881 - val_loss: 0.6803 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6856 - accuracy: 0.5719 - val_loss: 0.6796 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6869 - accuracy: 0.5700 - val_loss: 0.6796 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6831 - accuracy: 0.5788 - val_loss: 0.6794 - val_accuracy: 0.5791\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6921 - accuracy: 0.5444 - val_loss: 0.6877 - val_accuracy: 0.5456\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6863 - accuracy: 0.5500 - val_loss: 0.6781 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6849 - accuracy: 0.5569 - val_loss: 0.6784 - val_accuracy: 0.5791\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6866 - accuracy: 0.5506 - val_loss: 0.6786 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6751 - accuracy: 0.5987 - val_loss: 0.6774 - val_accuracy: 0.5794\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6749 - accuracy: 0.6000 - val_loss: 0.6773 - val_accuracy: 0.5794\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6865 - accuracy: 0.5431 - val_loss: 0.6783 - val_accuracy: 0.5794\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6635 - accuracy: 0.6288 - val_loss: 0.6845 - val_accuracy: 0.5794\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6832 - accuracy: 0.5794 - val_loss: 0.6796 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 6s - loss: 0.6138 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0067s vs `on_test_batch_end` time: 0.0179s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 23ms/step - loss: 0.6760 - accuracy: 0.5877\n",
      "training acc:  0.5793750286102295 , training loss:  0.6831557750701904 , val acc:  0.5793776512145996 , val loss:  0.6796242594718933 , test acc:  0.5876677632331848 , test loss:  0.6760026216506958\n",
      "\n",
      ". ,  $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.6078 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0074s vs `on_train_batch_end` time: 0.0126s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6892 - accuracy: 0.5813 - val_loss: 0.6872 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 7s 74ms/step - loss: 0.6878 - accuracy: 0.5781 - val_loss: 0.6857 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6771 - accuracy: 0.6019 - val_loss: 0.6858 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6908 - accuracy: 0.5550 - val_loss: 0.6845 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6860 - accuracy: 0.5744 - val_loss: 0.6835 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6828 - accuracy: 0.5863 - val_loss: 0.6830 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6923 - accuracy: 0.5512 - val_loss: 0.6822 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6737 - accuracy: 0.6131 - val_loss: 0.6855 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6842 - accuracy: 0.5788 - val_loss: 0.6806 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6885 - accuracy: 0.5412 - val_loss: 0.6804 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6811 - accuracy: 0.5813 - val_loss: 0.6798 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6738 - accuracy: 0.6056 - val_loss: 0.6799 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6834 - accuracy: 0.5738 - val_loss: 0.6787 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6744 - accuracy: 0.6012 - val_loss: 0.6793 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6895 - accuracy: 0.5487 - val_loss: 0.6798 - val_accuracy: 0.5546\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6724 - accuracy: 0.6050 - val_loss: 0.6773 - val_accuracy: 0.5794\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6867 - accuracy: 0.5512 - val_loss: 0.6772 - val_accuracy: 0.5794\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6758 - accuracy: 0.5931 - val_loss: 0.6787 - val_accuracy: 0.5794\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6741 - accuracy: 0.6012 - val_loss: 0.6768 - val_accuracy: 0.5794\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6918 - accuracy: 0.5306 - val_loss: 0.6833 - val_accuracy: 0.5580\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6846 - accuracy: 0.5500 - val_loss: 0.6771 - val_accuracy: 0.5794\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6816 - accuracy: 0.5806 - val_loss: 0.6772 - val_accuracy: 0.5678\n",
      "  1/596 [..............................] - ETA: 4s - loss: 0.6552 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0076s vs `on_test_batch_end` time: 0.0125s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 23ms/step - loss: 0.6754 - accuracy: 0.5762\n",
      "training acc:  0.5806249976158142 , training loss:  0.6815992593765259 , val acc:  0.56777423620224 , val loss:  0.6771767735481262 , test acc:  0.5762374401092529 , test loss:  0.6754111647605896\n",
      "\n",
      ". ,  $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input b understand site error far last c world come group large online working object fact que side course hard \\to makes method values layer important whether 5 next el original idea pretty got water called state amount current color test tried getting 10 assume    free kind common\n",
      "Epoch 1/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.7072 - accuracy: 0.5436WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_test_batch_end` time: 0.0130s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.7057 - accuracy: 0.5469 - val_loss: 0.6867 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6883 - accuracy: 0.5606 - val_loss: 0.6807 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6730 - accuracy: 0.6094 - val_loss: 0.6820 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6726 - accuracy: 0.6050 - val_loss: 0.6781 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6804 - accuracy: 0.5738 - val_loss: 0.6793 - val_accuracy: 0.5794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6795 - accuracy: 0.5788 - val_loss: 0.6790 - val_accuracy: 0.5506\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6798 - accuracy: 0.5619 - val_loss: 0.6765 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6803 - accuracy: 0.5744 - val_loss: 0.6763 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6696 - accuracy: 0.6094 - val_loss: 0.6822 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6772 - accuracy: 0.5788 - val_loss: 0.6791 - val_accuracy: 0.5559\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6723 - accuracy: 0.5775 - val_loss: 0.6764 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 7s - loss: 0.6271 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0063s vs `on_test_batch_end` time: 0.0138s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6734 - accuracy: 0.5877\n",
      "training acc:  0.5774999856948853 , training loss:  0.672272801399231 , val acc:  0.5793776512145996 , val loss:  0.6763840913772583 , test acc:  0.5876677632331848 , test loss:  0.6734362244606018\n",
      "\n",
      ". ,  $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input b understand site error far last c world come group large online working object fact que side course hard \\to makes method values layer important whether 5 next el original idea pretty got water called state amount current color test tried getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9459 - accuracy: 0.4631WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0077s vs `on_test_batch_end` time: 0.0145s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.9459 - accuracy: 0.4631 - val_loss: 0.6853 - val_accuracy: 0.5567\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6869 - accuracy: 0.5294 - val_loss: 0.6773 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6780 - accuracy: 0.5875 - val_loss: 0.6775 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6851 - accuracy: 0.5525 - val_loss: 0.6764 - val_accuracy: 0.5704\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6815 - accuracy: 0.5556 - val_loss: 0.6760 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6860 - accuracy: 0.5369 - val_loss: 0.6897 - val_accuracy: 0.5570\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6824 - accuracy: 0.5706 - val_loss: 0.6757 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6748 - accuracy: 0.5881 - val_loss: 0.6759 - val_accuracy: 0.5591\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6875 - accuracy: 0.5375 - val_loss: 0.6883 - val_accuracy: 0.5549\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6675 - accuracy: 0.6081 - val_loss: 0.6765 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 6s - loss: 0.6249 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0063s vs `on_test_batch_end` time: 0.0129s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6734 - accuracy: 0.5877\n",
      "training acc:  0.6081249713897705 , training loss:  0.6674501895904541 , val acc:  0.5793776512145996 , val loss:  0.6764829754829407 , test acc:  0.5876677632331848 , test loss:  0.6734246611595154\n",
      "\n",
      ". ,  $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input b understand site error far last c world come group large online working object fact que side course hard \\to makes method values layer important whether 5 next el original idea pretty got water called state amount current color test tried getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away energy google comes book search changes write low anyone everything provide exactly yes ai easy experience making < thought wrong fine multiple product language hand standard n thanks several game perhaps ask tell design ' year nothing lower although uses feel thus points update takes looks position useful\n",
      "Epoch 1/30\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.7008 - accuracy: 0.5255WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.7005 - accuracy: 0.5281 - val_loss: 0.6869 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6844 - accuracy: 0.5844 - val_loss: 0.6832 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6891 - accuracy: 0.5575 - val_loss: 0.6827 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6921 - accuracy: 0.5250 - val_loss: 0.6854 - val_accuracy: 0.5533\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6661 - accuracy: 0.6256 - val_loss: 0.6980 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6765 - accuracy: 0.6006 - val_loss: 0.6800 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6810 - accuracy: 0.5744 - val_loss: 0.6818 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6792 - accuracy: 0.5831 - val_loss: 0.6777 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6830 - accuracy: 0.5688 - val_loss: 0.6780 - val_accuracy: 0.5694\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6800 - accuracy: 0.5894 - val_loss: 0.6775 - val_accuracy: 0.5696\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6745 - accuracy: 0.5987 - val_loss: 0.6771 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6879 - accuracy: 0.5619 - val_loss: 0.6952 - val_accuracy: 0.5438\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6854 - accuracy: 0.5500 - val_loss: 0.6783 - val_accuracy: 0.5562\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6857 - accuracy: 0.5531 - val_loss: 0.6764 - val_accuracy: 0.5659\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6794 - accuracy: 0.5694 - val_loss: 0.6761 - val_accuracy: 0.5672\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6807 - accuracy: 0.5769 - val_loss: 0.6760 - val_accuracy: 0.5638\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6771 - accuracy: 0.5619 - val_loss: 0.6803 - val_accuracy: 0.5794\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6799 - accuracy: 0.5875 - val_loss: 0.6824 - val_accuracy: 0.5794\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6695 - accuracy: 0.6119 - val_loss: 0.6756 - val_accuracy: 0.5791\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6821 - accuracy: 0.5475 - val_loss: 0.6755 - val_accuracy: 0.5789\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6943 - accuracy: 0.5075 - val_loss: 0.6812 - val_accuracy: 0.5607\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6858 - accuracy: 0.5325 - val_loss: 0.6757 - val_accuracy: 0.5794\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6827 - accuracy: 0.5688 - val_loss: 0.6823 - val_accuracy: 0.5794\n",
      "  1/596 [..............................] - ETA: 7s - loss: 0.6034 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0077s vs `on_test_batch_end` time: 0.0137s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6782 - accuracy: 0.5877\n",
      "training acc:  0.5687500238418579 , training loss:  0.6826765537261963 , val acc:  0.5793776512145996 , val loss:  0.682329535484314 , test acc:  0.5876677632331848 , test loss:  0.6782065033912659\n",
      "\n",
      ". ,  $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input b understand site error far last c world come group large online working object fact que side course hard \\to makes method values layer important whether 5 next el original idea pretty got water called state amount current color test tried getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away energy google comes book search changes write low anyone everything provide exactly yes ai easy experience making < thought wrong fine multiple product language hand standard n thanks several game perhaps ask tell design ' year nothing lower although uses feel thus points update takes looks position useful added cases unless true clear return lens _ content higher effect price believe en almost view la model certain days string length files click context sentence others big normal gives step options turn english sort map terms close actual future seen link avoid allow network per problems easily \\\\ 100\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.7285 - accuracy: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0163s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6873 - accuracy: 0.5869 - val_loss: 0.6867 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6823 - accuracy: 0.5962 - val_loss: 0.6834 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6921 - accuracy: 0.5375 - val_loss: 0.6847 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6852 - accuracy: 0.5681 - val_loss: 0.6876 - val_accuracy: 0.5636\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6871 - accuracy: 0.5650 - val_loss: 0.6815 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6816 - accuracy: 0.5838 - val_loss: 0.6823 - val_accuracy: 0.5585\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6532 - accuracy: 0.6556 - val_loss: 0.6869 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6905 - accuracy: 0.5625 - val_loss: 0.6793 - val_accuracy: 0.5789\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6863 - accuracy: 0.5544 - val_loss: 0.6785 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6766 - accuracy: 0.5856 - val_loss: 0.6792 - val_accuracy: 0.5588\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6767 - accuracy: 0.5962 - val_loss: 0.6780 - val_accuracy: 0.5620\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6840 - accuracy: 0.5656 - val_loss: 0.6771 - val_accuracy: 0.5791\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6739 - accuracy: 0.6000 - val_loss: 0.6773 - val_accuracy: 0.5609\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6832 - accuracy: 0.5519 - val_loss: 0.6779 - val_accuracy: 0.5575\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6766 - accuracy: 0.5894 - val_loss: 0.6763 - val_accuracy: 0.5791\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6747 - accuracy: 0.5900 - val_loss: 0.6761 - val_accuracy: 0.5604\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 80ms/step - loss: 0.6703 - accuracy: 0.5919 - val_loss: 0.6760 - val_accuracy: 0.5794\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6795 - accuracy: 0.5800 - val_loss: 0.6785 - val_accuracy: 0.5794\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6771 - accuracy: 0.5763 - val_loss: 0.6790 - val_accuracy: 0.5794\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6863 - accuracy: 0.5544 - val_loss: 0.6829 - val_accuracy: 0.5588\n",
      "  1/596 [..............................] - ETA: 3s - loss: 0.6977 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0079s vs `on_test_batch_end` time: 0.0126s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6832 - accuracy: 0.5633\n",
      "training acc:  0.5543749928474426 , training loss:  0.6863294839859009 , val acc:  0.5588080286979675 , val loss:  0.6829063296318054 , test acc:  0.5633389353752136 , test loss:  0.6831761002540588\n",
      "\n",
      ". ,  $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input b understand site error far last c world come group large online working object fact que side course hard \\to makes method values layer important whether 5 next el original idea pretty got water called state amount current color test tried getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away energy google comes book search changes write low anyone everything provide exactly yes ai easy experience making < thought wrong fine multiple product language hand standard n thanks several game perhaps ask tell design ' year nothing lower although uses feel thus points update takes looks position useful added cases unless true clear return lens _ content higher effect price believe en almost view la model certain days string length files click context sentence others big normal gives step options turn english sort map terms close actual future seen link avoid allow network per problems easily \\\\ 100 meaning main client computer known smaller tool difficult please research save whole generally setting bad mind transaction functions choose sometimes therefore sound ones related instance   characters along play images mode move database cause rate gets support yet table e says background examples web money head reading random inside n$\n",
      "Epoch 1/30\n",
      "  1/100 [..............................] - ETA: 0s - loss: 0.7685 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0169s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6951 - accuracy: 0.5550 - val_loss: 0.6923 - val_accuracy: 0.5282\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6955 - accuracy: 0.5088 - val_loss: 0.6916 - val_accuracy: 0.5609\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6772 - accuracy: 0.6206 - val_loss: 0.6863 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6918 - accuracy: 0.5462 - val_loss: 0.6819 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6855 - accuracy: 0.5813 - val_loss: 0.6807 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6793 - accuracy: 0.5925 - val_loss: 0.6791 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6901 - accuracy: 0.5238 - val_loss: 0.6780 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6753 - accuracy: 0.6006 - val_loss: 0.6785 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6820 - accuracy: 0.5644 - val_loss: 0.6776 - val_accuracy: 0.5614\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6862 - accuracy: 0.5512 - val_loss: 0.6768 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6805 - accuracy: 0.5744 - val_loss: 0.6762 - val_accuracy: 0.5794\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6884 - accuracy: 0.5306 - val_loss: 0.6803 - val_accuracy: 0.5607\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6895 - accuracy: 0.5512 - val_loss: 0.6775 - val_accuracy: 0.5607\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6857 - accuracy: 0.5369 - val_loss: 0.6793 - val_accuracy: 0.5617\n",
      "  1/596 [..............................] - ETA: 6s - loss: 0.6812 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_test_batch_end` time: 0.0015s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6793 - accuracy: 0.5706\n",
      "training acc:  0.5368750095367432 , training loss:  0.6857248544692993 , val acc:  0.5617088675498962 , val loss:  0.6793484687805176 , test acc:  0.5705746412277222 , test loss:  0.6793224215507507\n",
      "\n",
      ". ,  $   's n't would   one like use / also get could time need way using make want 'm work - see first two think even know 1 example may people = different used might much something question 've well case 're set good however number 2 find try new problem say since really many take still possible data answer right another code go point change without value probably things page + better image let ca sure create add back url$ enough actually 'd look 'll system 3 function able file every going long following given    seems second thing part though help around either best lot give etc always x form high note > means power order less check list edit found must bit solution based start made trying % done end option least likely run field & key size \\mathcal word server keep small type 0 already text user read anything works    line maybe instead little version correct day similar looking light rather issue non us information person someone specific output reason single mean result space name de times said simple open quite simply never level show process put years place real often usually input b understand site error far last c world come group large online working object fact que side course hard \\to makes method values layer important whether 5 next el original idea pretty got water called state amount current color test tried getting 10 assume    free kind common    bytes left wo else words call character general sense seem block difference past consider post top matter results created available source full old term 4 great running life range control class address particular god numbers camera three paper human within i.e. e.g. account select access due short # needs area away energy google comes book search changes write low anyone everything provide exactly yes ai easy experience making < thought wrong fine multiple product language hand standard n thanks several game perhaps ask tell design ' year nothing lower although uses feel thus points update takes looks position useful added cases unless true clear return lens _ content higher effect price believe en almost view la model certain days string length files click context sentence others big normal gives step options turn english sort map terms close actual future seen link avoid allow network per problems easily \\\\ 100 meaning main client computer known smaller tool difficult please research save whole generally setting bad mind transaction functions choose sometimes therefore sound ones related instance   characters along play images mode move database cause rate gets support yet table e says background examples web money head reading random inside n$ rules happen taking guess approach mm pages hope via 6 depends explanation photoshop assuming build default become company application air users windows body apply bitcoin later directly writing custom target program rule situation story structure exact parts local stop longer remove algorithm sequence limit service history job larger whatever half\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/100 [..............................] - ETA: 0s - loss: 0.5694 - accuracy: 0.8125WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0074s vs `on_train_batch_end` time: 0.0135s). Check your callbacks.\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.6902 - accuracy: 0.5976WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0066s vs `on_test_batch_end` time: 0.0133s). Check your callbacks.\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6908 - accuracy: 0.5956 - val_loss: 0.6910 - val_accuracy: 0.5396\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6893 - accuracy: 0.5725 - val_loss: 0.6909 - val_accuracy: 0.5794\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6895 - accuracy: 0.5675 - val_loss: 0.6875 - val_accuracy: 0.5794\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6806 - accuracy: 0.5931 - val_loss: 0.6874 - val_accuracy: 0.5794\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6896 - accuracy: 0.5825 - val_loss: 0.6875 - val_accuracy: 0.5794\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6879 - accuracy: 0.5625 - val_loss: 0.6829 - val_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6914 - accuracy: 0.5594 - val_loss: 0.6809 - val_accuracy: 0.5794\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6680 - accuracy: 0.6275 - val_loss: 0.6846 - val_accuracy: 0.5794\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6848 - accuracy: 0.5781 - val_loss: 0.6790 - val_accuracy: 0.5794\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6894 - accuracy: 0.5213 - val_loss: 0.6793 - val_accuracy: 0.5794\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6830 - accuracy: 0.5719 - val_loss: 0.6784 - val_accuracy: 0.5659\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6827 - accuracy: 0.5769 - val_loss: 0.6772 - val_accuracy: 0.5794\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6731 - accuracy: 0.6044 - val_loss: 0.6781 - val_accuracy: 0.5794\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.6806 - accuracy: 0.5612 - val_loss: 0.6770 - val_accuracy: 0.5794\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 7s 75ms/step - loss: 0.6736 - accuracy: 0.5888 - val_loss: 0.6754 - val_accuracy: 0.5699\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.6811 - accuracy: 0.5500 - val_loss: 0.6754 - val_accuracy: 0.5604\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.6868 - accuracy: 0.5356 - val_loss: 0.6842 - val_accuracy: 0.5585\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 0.6855 - accuracy: 0.5375 - val_loss: 0.6758 - val_accuracy: 0.5630\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.6764 - accuracy: 0.5744 - val_loss: 0.6757 - val_accuracy: 0.5633\n",
      "  1/596 [..............................] - ETA: 6s - loss: 0.6646 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_test_batch_end` time: 0.0121s). Check your callbacks.\n",
      "596/596 [==============================] - 14s 24ms/step - loss: 0.6749 - accuracy: 0.5650\n",
      "training acc:  0.5743749737739563 , training loss:  0.6763713359832764 , val acc:  0.5632911324501038 , val loss:  0.6757152080535889 , test acc:  0.5650168061256409 , test loss:  0.6748518347740173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "for key in list(feature_set_files.keys()):\n",
    "    print(key)\n",
    "    temp_metrics_dict={}\n",
    "    vocab_files = []\n",
    "    training_acc = []\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    validation_acc = []\n",
    "    testing_acc= []\n",
    "    testing_loss = []\n",
    "    vocab_size_list = []\n",
    "    print(key, feature_set_files.get(key))\n",
    "    for feature_file in feature_set_files.get(key):\n",
    "        word_tokenizer = Tokenizer(analyzer=custom_analyzer)\n",
    "        with open(feature_file, \"r\") as f:\n",
    "            word_index_str = f.read().replace('\\n', '')\n",
    "        print(word_index_str)\n",
    "        word_tokenizer.fit_on_texts([word_index_str])\n",
    "        len_train = len(training_data)\n",
    "        # define the generators\n",
    "        from src.DataGenerator import DataGenerator\n",
    "        training_generator = DataGenerator(training_data.iloc[0:int(0.8*len_train)], tokenizer=word_tokenizer, batch_size=16)\n",
    "        validation_generator = DataGenerator(training_data.iloc[int(0.8*len_train):], tokenizer=word_tokenizer, batch_size=16)\n",
    "        testing_generator = DataGenerator(testing_data, tokenizer=word_tokenizer, batch_size=16)\n",
    "\n",
    "        # this is a hack for \"'DataGenerator' object has no attribute 'index'\". It turns out that on_epoch_end creates the index that is used\n",
    "        training_generator.on_epoch_end()\n",
    "        validation_generator.on_epoch_end()\n",
    "        testing_generator.on_epoch_end()\n",
    "        # parameters\n",
    "        num_classes =2\n",
    "        num_features = 1\n",
    "\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(50, input_dim=num_features, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        # compile model\n",
    "        opt = SGD(lr=0.01, momentum=0.9)\n",
    "        #model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        # fit model\n",
    "        history = model.fit(training_generator, validation_data=validation_generator, verbose=1, batch_size=16, \n",
    "                             epochs=30, steps_per_epoch=100, callbacks=[callback]) #validation_steps=100,\n",
    "\n",
    "        history_dict = history.history\n",
    "        vocab_files.append(feature_file.split('/')[-1])\n",
    "        json.dump(history_dict, open(\"history_\" + key + \"_\" +feature_file.split('/')[-1], 'w'))\n",
    "        loss = history_dict['loss'][-1]\n",
    "        training_loss.append(loss)\n",
    "        acc = history_dict['accuracy'][-1]\n",
    "        training_acc.append(acc)\n",
    "        val_loss = history_dict['val_loss'][-1]\n",
    "        validation_loss.append(val_loss)\n",
    "        val_acc = history_dict['val_accuracy'][-1]\n",
    "        validation_acc.append(val_acc)\n",
    "        test_loss, test_acc = model.evaluate(testing_generator)\n",
    "        testing_acc.append(test_acc)\n",
    "        testing_loss.append(test_loss)\n",
    "        vocab_size_list.append(feature_file.split('/')[-1])\n",
    "        print(\"training acc: \", acc, \", training loss: \", loss, \", val acc: \", val_acc, \", val loss: \", val_loss,\", test acc: \", test_acc, \", test loss: \", test_loss)\n",
    "        print()\n",
    "    temp_metrics_dict={'vocab_size':vocab_size_list,\n",
    "        'training_loss' : training_loss,\n",
    "         'training_acc': training_acc,\n",
    "         'validation_loss': validation_loss,\n",
    "         'validation_acc': validation_acc,\n",
    "         'testing_loss':testing_loss,\n",
    "         'testing_acc':testing_acc}\n",
    "    json.dump(temp_metrics_dict, open(\"total_history_\" + key, 'w'))\n",
    "    metrics[key] = temp_metrics_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(metrics, open(\"history/total_history_combined\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt1 = pd.DataFrame(metrics.get('opt1'))\n",
    "df_opt2 = pd.DataFrame(metrics.get('opt2'))\n",
    "df_opt3 = pd.DataFrame(metrics.get('opt3'))\n",
    "df_opt4 = pd.DataFrame(metrics.get('opt4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>training_acc</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>testing_loss</th>\n",
       "      <th>testing_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50word_list.txt</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.6025</td>\n",
       "      <td>0.661470</td>\n",
       "      <td>0.599913</td>\n",
       "      <td>0.660793</td>\n",
       "      <td>0.590235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100word_list.txt</td>\n",
       "      <td>0.656294</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>0.658305</td>\n",
       "      <td>0.594183</td>\n",
       "      <td>0.659788</td>\n",
       "      <td>0.585102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         vocab_size  training_loss  training_acc  validation_loss  \\\n",
       "0   50word_list.txt       0.658537        0.6025         0.661470   \n",
       "1  100word_list.txt       0.656294        0.6050         0.658305   \n",
       "\n",
       "   validation_acc  testing_loss  testing_acc  \n",
       "0        0.599913      0.660793     0.590235  \n",
       "1        0.594183      0.659788     0.585102  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_opt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>training_acc</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>testing_loss</th>\n",
       "      <th>testing_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>opt1</th>\n",
       "      <td>100word_list.txt</td>\n",
       "      <td>0.656294</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.658305</td>\n",
       "      <td>0.594183</td>\n",
       "      <td>0.659788</td>\n",
       "      <td>0.585102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            vocab_size  training_loss  training_acc  validation_loss  \\\n",
       "opt1  100word_list.txt       0.656294         0.605         0.658305   \n",
       "\n",
       "      validation_acc  testing_loss  testing_acc  \n",
       "opt1        0.594183      0.659788     0.585102  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df_1 = df_opt1.loc[df_opt1['vocab_size'] == '100word_list.txt'].copy()\n",
    "temp_df_1.index= [\"opt1\"]\n",
    "temp_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>training_acc</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>testing_loss</th>\n",
       "      <th>testing_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>opt2</th>\n",
       "      <td>100word_list.txt</td>\n",
       "      <td>0.630891</td>\n",
       "      <td>0.630625</td>\n",
       "      <td>0.638632</td>\n",
       "      <td>0.614187</td>\n",
       "      <td>0.6476</td>\n",
       "      <td>0.602873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            vocab_size  training_loss  training_acc  validation_loss  \\\n",
       "opt2  100word_list.txt       0.630891      0.630625         0.638632   \n",
       "\n",
       "      validation_acc  testing_loss  testing_acc  \n",
       "opt2        0.614187        0.6476     0.602873  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df_2 = df_opt2.loc[df_opt2['vocab_size'] == '100word_list.txt'].copy()\n",
    "temp_df_2.index= [\"opt2\"]\n",
    "temp_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>training_acc</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>testing_loss</th>\n",
       "      <th>testing_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>opt3</th>\n",
       "      <td>100word_list.txt</td>\n",
       "      <td>0.647728</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.650469</td>\n",
       "      <td>0.613862</td>\n",
       "      <td>0.649569</td>\n",
       "      <td>0.611586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            vocab_size  training_loss  training_acc  validation_loss  \\\n",
       "opt3  100word_list.txt       0.647728        0.6125         0.650469   \n",
       "\n",
       "      validation_acc  testing_loss  testing_acc  \n",
       "opt3        0.613862      0.649569     0.611586  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df_3 = df_opt3.loc[df_opt3['vocab_size'] == '100word_list.txt'].copy()\n",
    "temp_df_3.index= [\"opt3\"]\n",
    "temp_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>training_acc</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>testing_loss</th>\n",
       "      <th>testing_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>opt4</th>\n",
       "      <td>100word_list.txt</td>\n",
       "      <td>0.615623</td>\n",
       "      <td>0.636875</td>\n",
       "      <td>0.61408</td>\n",
       "      <td>0.64814</td>\n",
       "      <td>0.616221</td>\n",
       "      <td>0.647084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            vocab_size  training_loss  training_acc  validation_loss  \\\n",
       "opt4  100word_list.txt       0.615623      0.636875          0.61408   \n",
       "\n",
       "      validation_acc  testing_loss  testing_acc  \n",
       "opt4         0.64814      0.616221     0.647084  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df_4 = df_opt4.loc[df_opt4['vocab_size'] == '100word_list.txt'].copy()\n",
    "temp_df_4.index= [\"opt4\"]\n",
    "temp_df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([temp_df_1,temp_df_2,temp_df_3, temp_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>training_acc</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>testing_loss</th>\n",
       "      <th>testing_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>opt1</th>\n",
       "      <td>100word_list.txt</td>\n",
       "      <td>0.656294</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.658305</td>\n",
       "      <td>0.594183</td>\n",
       "      <td>0.659788</td>\n",
       "      <td>0.585102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt2</th>\n",
       "      <td>100word_list.txt</td>\n",
       "      <td>0.630891</td>\n",
       "      <td>0.630625</td>\n",
       "      <td>0.638632</td>\n",
       "      <td>0.614187</td>\n",
       "      <td>0.647600</td>\n",
       "      <td>0.602873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt3</th>\n",
       "      <td>100word_list.txt</td>\n",
       "      <td>0.647728</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.650469</td>\n",
       "      <td>0.613862</td>\n",
       "      <td>0.649569</td>\n",
       "      <td>0.611586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt4</th>\n",
       "      <td>100word_list.txt</td>\n",
       "      <td>0.615623</td>\n",
       "      <td>0.636875</td>\n",
       "      <td>0.614080</td>\n",
       "      <td>0.648140</td>\n",
       "      <td>0.616221</td>\n",
       "      <td>0.647084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            vocab_size  training_loss  training_acc  validation_loss  \\\n",
       "opt1  100word_list.txt       0.656294      0.605000         0.658305   \n",
       "opt2  100word_list.txt       0.630891      0.630625         0.638632   \n",
       "opt3  100word_list.txt       0.647728      0.612500         0.650469   \n",
       "opt4  100word_list.txt       0.615623      0.636875         0.614080   \n",
       "\n",
       "      validation_acc  testing_loss  testing_acc  \n",
       "opt1        0.594183      0.659788     0.585102  \n",
       "opt2        0.614187      0.647600     0.602873  \n",
       "opt3        0.613862      0.649569     0.611586  \n",
       "opt4        0.648140      0.616221     0.647084  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8e831fcca0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result[['training_acc', 'validation_acc', 'testing_acc']].plot.bar(rot=0).legend(loc='center left',bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8e832184c0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result[['training_acc', 'validation_acc', 'testing_acc']].plot.bar(rot=0).legend(loc='center left',bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (SiameseNetworkTensorflow)",
   "language": "python",
   "name": "pycharm-edf9727a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}