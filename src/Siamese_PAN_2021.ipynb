{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import config\n",
    "from spacy.lang.en import English\n",
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Concatenate,GlobalMaxPool2D,Multiply\n",
    "from tensorflow.keras.layers import Dropout, Subtract, Add, GlobalAvgPool2D, Conv2D, Bidirectional\n",
    "from tensorflow.keras.layers import Flatten, Dense, Embedding, LSTM, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization, MaxPooling2D, Concatenate, Lambda\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training file from path:  /home/sukanya/PhD/Datasets/PAN SCD/pan21-style-change-detection/processed/train.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>author_1</th>\n",
       "      <th>author_2</th>\n",
       "      <th>para1_text</th>\n",
       "      <th>para2_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem-4845.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>I can't see the names (as you've properly reda...</td>\n",
       "      <td>Does it have anything to do that in this parti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem-4845.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Does it have anything to do that in this parti...</td>\n",
       "      <td>I am having a problem with connectivity in one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>problem-4845.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I am having a problem with connectivity in one...</td>\n",
       "      <td>Aliases are a way for the client to be redirec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem-4845.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Aliases are a way for the client to be redirec...</td>\n",
       "      <td>It doesn't deal with any of that. It specifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem-9721.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>There is no non-root command, but a root comma...</td>\n",
       "      <td>For my situation, the use of locking is not su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            problem  author_1  author_2  \\\n",
       "0  problem-4845.txt         1         2   \n",
       "1  problem-4845.txt         2         2   \n",
       "2  problem-4845.txt         2         1   \n",
       "3  problem-4845.txt         1         1   \n",
       "4  problem-9721.txt         1         2   \n",
       "\n",
       "                                          para1_text  \\\n",
       "0  I can't see the names (as you've properly reda...   \n",
       "1  Does it have anything to do that in this parti...   \n",
       "2  I am having a problem with connectivity in one...   \n",
       "3  Aliases are a way for the client to be redirec...   \n",
       "4  There is no non-root command, but a root comma...   \n",
       "\n",
       "                                          para2_text  \n",
       "0  Does it have anything to do that in this parti...  \n",
       "1  I am having a problem with connectivity in one...  \n",
       "2  Aliases are a way for the client to be redirec...  \n",
       "3  It doesn't deal with any of that. It specifica...  \n",
       "4  For my situation, the use of locking is not su...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading training file from path: \", config.config_io.get('pan_21_processed_train'))\n",
    "training_data = pd.read_csv(config.config_io.get('pan_21_processed_train'))\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[\"is_diff_author\"] = (training_data['author_1'] != training_data['author_2']).astype(int).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>author_1</th>\n",
       "      <th>author_2</th>\n",
       "      <th>para1_text</th>\n",
       "      <th>para2_text</th>\n",
       "      <th>is_diff_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem-4845.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>I can't see the names (as you've properly reda...</td>\n",
       "      <td>Does it have anything to do that in this parti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem-4845.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Does it have anything to do that in this parti...</td>\n",
       "      <td>I am having a problem with connectivity in one...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>problem-4845.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I am having a problem with connectivity in one...</td>\n",
       "      <td>Aliases are a way for the client to be redirec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem-4845.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Aliases are a way for the client to be redirec...</td>\n",
       "      <td>It doesn't deal with any of that. It specifica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem-9721.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>There is no non-root command, but a root comma...</td>\n",
       "      <td>For my situation, the use of locking is not su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            problem  author_1  author_2  \\\n",
       "0  problem-4845.txt         1         2   \n",
       "1  problem-4845.txt         2         2   \n",
       "2  problem-4845.txt         2         1   \n",
       "3  problem-4845.txt         1         1   \n",
       "4  problem-9721.txt         1         2   \n",
       "\n",
       "                                          para1_text  \\\n",
       "0  I can't see the names (as you've properly reda...   \n",
       "1  Does it have anything to do that in this parti...   \n",
       "2  I am having a problem with connectivity in one...   \n",
       "3  Aliases are a way for the client to be redirec...   \n",
       "4  There is no non-root command, but a root comma...   \n",
       "\n",
       "                                          para2_text  is_diff_author  \n",
       "0  Does it have anything to do that in this parti...               1  \n",
       "1  I am having a problem with connectivity in one...               0  \n",
       "2  Aliases are a way for the client to be redirec...               1  \n",
       "3  It doesn't deal with any of that. It specifica...               0  \n",
       "4  For my situation, the use of locking is not su...               1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this portion will eventually be replaced by a proper data generator which will give batches\n",
    "n = len(training_data)\n",
    "x_train = training_data[0:int(n*0.1)][['para1_text', 'para2_text']]\n",
    "x_val = training_data[int(n*0.1): int(n*0.15)][['para1_text', 'para2_text']]\n",
    "y_train = training_data[0:int(n*0.1)][['is_diff_author']]\n",
    "y_val = training_data[int(n*0.1): int(n*0.15):][['is_diff_author']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3302, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = x_train[\"para1_text\"] + \" \" + x_train[\"para2_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "t = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "t.fit_on_texts(combined.values)\n",
    "sequences = tok.texts_to_sequences(combined)\n",
    "sequences = pad_sequences(sequences, maxlen=300, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p1_seq = t.texts_to_sequences(x_train['para1_text'].values)\n",
    "train_p2_seq = t.texts_to_sequences(x_train['para2_text'].values)\n",
    "val_p1_seq = t.texts_to_sequences(x_val['para1_text'].values)\n",
    "val_p2_seq = t.texts_to_sequences(x_val['para2_text'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6605"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_p1_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_len = [len(sent_vec) for sent_vec in train_p1_seq] + [len(sent_vec) for sent_vec in train_p2_seq]\n",
    "max_len = max(vec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9.033e+03, 3.494e+03, 5.390e+02, 1.010e+02, 2.800e+01, 1.100e+01,\n",
       "        0.000e+00, 2.000e+00, 0.000e+00, 2.000e+00]),\n",
       " array([  8. ,  49.6,  91.2, 132.8, 174.4, 216. , 257.6, 299.2, 340.8,\n",
       "        382.4, 424. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(vec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most of the values are less than say len 100, so we can infact try with length 200 and see how that goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 300\n",
    "train_p1_seq = pad_sequences(train_p1_seq, maxlen=max_len, padding='post')\n",
    "train_p2_seq = pad_sequences(train_p2_seq, maxlen=max_len, padding='post')\n",
    "val_p1_seq = pad_sequences(val_p1_seq, maxlen=max_len, padding='post')\n",
    "val_p2_seq = pad_sequences(val_p2_seq, maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('/home/sukanya/PhD/Embeddings/Glove/glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_embed_matrix(t, embeddings_index, embedding_vector_size = 50):\n",
    "    \"\"\"\n",
    "    t: tokenizer\n",
    "    \n",
    "    \"\"\"\n",
    "    not_present_list = []\n",
    "    vocab_size = len(t.word_index) + 1\n",
    "    embedding_matrix = np.zeros((vocab_size, len(embeddings_index['no'])))\n",
    "    for word, i in t.word_index.items():\n",
    "        embedding_vector = None\n",
    "        if word in embeddings_index.keys():\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "        else:\n",
    "            not_present_list.append(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            embedding_matrix[i] = np.zeros(embedding_vector_size) # size of the embedding\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "embed_matrix = get_glove_embed_matrix(t, embeddings_index, embedding_vector_size = embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15962, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p1_seq.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-a60b77382778>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m#input_2 = Input(shape=(train_p2_seq.shape[1],))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0minput1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mInput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m300\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0minput2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mInput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m300\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "input_1 = Input(shape=(train_p1_seq.shape[1],))\n",
    "input_2 = Input(shape=(train_p2_seq.shape[1],))\n",
    "\n",
    "\n",
    "lstm_layer = Bidirectional(LSTM(10, dropout=0.2, recurrent_dropout=0.2))\n",
    "#tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2))# loading our matrix\n",
    "# max_words 10000 , embedding_dim = 50, max_len = 100\n",
    "emb =  Embedding(15962, embedding_dim, input_length=max_len, weights=[embed_matrix],trainable=False)\n",
    "\n",
    "e1 = emb(input1)\n",
    "x1 = lstm_layer(e1)\n",
    "e2 = emb(input2)\n",
    "x2 = lstm_layer(e2)\n",
    "\n",
    "\n",
    "mhd = lambda x: tf.keras.backend.abs(x[0] - x[1])\n",
    "\n",
    "\n",
    "merged = tf.keras.layers.Lambda(function=mhd, output_shape=lambda x: x[0],\n",
    "name='L1_distance')([x1, x2])\n",
    "preds = tf.keras.layers.Dense(1, activation='sigmoid')(merged)\n",
    "model = tf.keras.Model(inputs=[input1, input2], outputs=preds)\n",
    "model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 300, 50)      798100      input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 20)           4880        embedding_6[0][0]                \n",
      "                                                                 embedding_6[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "L1_distance (Lambda)            (None, 20)           0           bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            21          L1_distance[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 803,001\n",
      "Trainable params: 4,901\n",
      "Non-trainable params: 798,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "104/104 [==============================] - 29s 236ms/step - loss: 0.6994 - acc: 0.4839 - val_loss: 0.7037 - val_acc: 0.4334\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 28s 272ms/step - loss: 0.7011 - acc: 0.4711 - val_loss: 0.7033 - val_acc: 0.4352\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 27s 261ms/step - loss: 0.6993 - acc: 0.4714 - val_loss: 0.7029 - val_acc: 0.4352\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 27s 262ms/step - loss: 0.6979 - acc: 0.4845 - val_loss: 0.7025 - val_acc: 0.4349\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 28s 269ms/step - loss: 0.7007 - acc: 0.4646 - val_loss: 0.7022 - val_acc: 0.4376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f46e799c250>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_p1_seq,train_p2_seq],y_train.values.reshape(-1,1), epochs = 20,\n",
    "          batch_size=64,validation_data=([val_p1_seq, val_p2_seq],y_val.values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 4s 39ms/step - loss: 0.7022 - acc: 0.4376\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate([val_p1_seq, val_p2_seq], y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4376135766506195"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (SiameseNetworkTensorflow)",
   "language": "python",
   "name": "pycharm-edf9727a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}